{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summary of the requested runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_run = 1703\n",
    "to_run = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_dict(paths_dict: dict) -> dict:\n",
    "    result = {}\n",
    "    #dir_contents: list = []\n",
    "    for key in paths_dict:\n",
    "        if key != \"working_dir\":\n",
    "            dir_contents = os.listdir(paths_dict[key])\n",
    "    \n",
    "            #numbers = []\n",
    "            #rest_of_file_name: str = \"\"\n",
    "            for entry in dir_contents:\n",
    "                number = 0\n",
    "                if \"_\" in entry:\n",
    "                    number = int(entry.split(\"_\")[0])\n",
    "                    #rest_of_file_name = str.join(\"_\", entry.split(\"_\")[1:])\n",
    "                    \n",
    "                else:\n",
    "                    number = int(entry.split(\".\")[0])\n",
    "                    #rest_of_file_name = str.join(\".\", entry.split(\".\")[1:])\n",
    "                    \n",
    "                if number not in result:\n",
    "                    result[number] = {}\n",
    "                    \n",
    "                result[number][key] = paths_dict[key] / f\"{entry}\"\n",
    "    #if not numbers:\n",
    "    #    return []\n",
    "    \n",
    "            #for num in numbers:\n",
    "                \n",
    "    \n",
    "    # Remove double entries and sort.\n",
    "    #result = dict.fromkeys(numbers)\n",
    "    #result.sort()\n",
    "\n",
    "    #for key in result:\n",
    "    #    result[key] = {}\n",
    "    #    result[key][\"summary_path\"] = paths_dict[\"summaries_dir\"] / f\"{key}_summary.json\"\n",
    "    #    result[key][\"result_path\"] = paths_dict[\"summaries_dir\"] / f\"{key}_summary.json\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_reward_std(path: Path) -> tuple[float, float]:\n",
    "    \"\"\"Get the mean reward over the last 5 cumulative rewards entries in the tfevents file.\"\"\"\n",
    "    cumulative_rewards = []\n",
    "\n",
    "    # Get the tfevents file associated with the current run.\n",
    "    path_to_result_folder = path / \"RollerAgent/\"\n",
    "    try:\n",
    "        path_to_result = sorted(Path(path_to_result_folder).glob(\"events.out.tfevents.*\"))[0]\n",
    "    except:\n",
    "        return 0,0\n",
    "\n",
    "    # Using tensorflow to access the tfevents data.\n",
    "    # datarecord = EventFileLoader(str(path_to_result)).Load()\n",
    "    for event in EventFileLoader(str(path_to_result)).Load():\n",
    "        # event = event_pb2.Event.FromString(batch.numpy())\n",
    "        for value in event.summary.value:\n",
    "            if value.tag == \"Environment/Cumulative Reward\":\n",
    "                cumulative_rewards.append(value.tensor.float_val[0])\n",
    "\n",
    "    # Return mean of the last 5 recorded cummulative rewards.\n",
    "    rewards_of_interest = cumulative_rewards[-100:]\n",
    "    return np.mean(rewards_of_interest), np.round(np.std(rewards_of_interest), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'working_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env'),\n",
       " 'results_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/results'),\n",
       " 'results_archive_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/results_archive'),\n",
       " 'stats_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/stats'),\n",
       " 'summaries_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/summaries'),\n",
       " 'configs_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/configs'),\n",
       " 'unity_configs_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/unity_configs')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter paths for plot creation and get absolute paths.\n",
    "paths = {\n",
    "        \"working_dir\": \"C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env\",\n",
    "        \"results_dir\": \"results/\",\n",
    "        \"results_archive_dir\": \"results_archive/\",\n",
    "        \"stats_dir\": \"stats/\",\n",
    "        \"summaries_dir\": \"summaries/\",\n",
    "        \"configs_dir\": \"configs/\",\n",
    "        \"unity_configs_dir\": \"unity_configs/\"\n",
    "    }\n",
    "\n",
    "paths[\"working_dir\"] = Path(paths[\"working_dir\"]).absolute()\n",
    "\n",
    "for key in paths:\n",
    "    if key != \"working_dir\":\n",
    "        paths[key] = paths[\"working_dir\"] / paths[key]\n",
    "        \n",
    "\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1703,\n",
       " 1706,\n",
       " 1751,\n",
       " 1758,\n",
       " 1770,\n",
       " 1793,\n",
       " 1808,\n",
       " 1842,\n",
       " 1891,\n",
       " 1895,\n",
       " 1928,\n",
       " 1949,\n",
       " 1968,\n",
       " 2032,\n",
       " 2045,\n",
       " 2270,\n",
       " 2303,\n",
       " 2323,\n",
       " 2341,\n",
       " 2352,\n",
       " 2439,\n",
       " 2503,\n",
       " 2518,\n",
       " 2560,\n",
       " 2573,\n",
       " 2699,\n",
       " 2744,\n",
       " 2958,\n",
       " 2979,\n",
       " 2996,\n",
       " 3005,\n",
       " 3035,\n",
       " 3036,\n",
       " 3061,\n",
       " 3087,\n",
       " 3091,\n",
       " 3108,\n",
       " 3134,\n",
       " 3192,\n",
       " 3243,\n",
       " 3272,\n",
       " 3295,\n",
       " 3378,\n",
       " 3548,\n",
       " 3572,\n",
       " 3579,\n",
       " 3580,\n",
       " 3632,\n",
       " 3657,\n",
       " 3717,\n",
       " 3734,\n",
       " 3751,\n",
       " 3765,\n",
       " 3788,\n",
       " 3818,\n",
       " 3876,\n",
       " 3923,\n",
       " 4015,\n",
       " 4110,\n",
       " 4121,\n",
       " 4192,\n",
       " 4204,\n",
       " 4209,\n",
       " 4244,\n",
       " 4289,\n",
       " 4342,\n",
       " 4376,\n",
       " 4392,\n",
       " 4479,\n",
       " 4499,\n",
       " 4571,\n",
       " 4602,\n",
       " 4654,\n",
       " 4776,\n",
       " 4888,\n",
       " 5005,\n",
       " 5009,\n",
       " 5027,\n",
       " 5043,\n",
       " 5102,\n",
       " 5136,\n",
       " 5168,\n",
       " 5204,\n",
       " 5208,\n",
       " 5227,\n",
       " 5246,\n",
       " 5266,\n",
       " 5315,\n",
       " 5316,\n",
       " 5330,\n",
       " 5370,\n",
       " 5385,\n",
       " 5395,\n",
       " 5413,\n",
       " 5426,\n",
       " 5430,\n",
       " 5529,\n",
       " 5617,\n",
       " 5629,\n",
       " 5635,\n",
       " 5662,\n",
       " 5679,\n",
       " 5754,\n",
       " 5809,\n",
       " 5866,\n",
       " 5941,\n",
       " 5956]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dict = get_run_dict(paths)\n",
    "\n",
    "selected_ids = [x for x in run_dict.keys() if from_run <= x <= to_run]\n",
    "selected_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids_dict = {}\n",
    "for run_id in selected_ids:\n",
    "    selected_ids_dict[run_id] = {}\n",
    "\n",
    "    if \"stats_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"stats_dir\"]) as json_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"stats\"] = json.load(json_file)\n",
    "    \n",
    "    if \"unity_configs_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"unity_configs_dir\"]) as json_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"unity_config\"] = json.load(json_file)\n",
    "\n",
    "    if \"configs_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"configs_dir\"]) as yaml_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"training_config\"] = yaml.safe_load(yaml_file)\n",
    "    \n",
    "    if \"results_dir\" in run_dict[run_id]:\n",
    "        selected_ids_dict[run_id][\"mean_reward\"], selected_ids_dict[run_id][\"std_reward\"] = get_mean_reward_std(run_dict[run_id][\"results_dir\"])\n",
    "\n",
    "#selected_ids_dict[4015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1703,\n",
       "              {'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1703,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1703_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': 0,\n",
       "               'std_reward': 0}),\n",
       "             (5005,\n",
       "              {'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5005,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5005_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': 0,\n",
       "               'std_reward': 0}),\n",
       "             (2341,\n",
       "              {'stats': {'sameRoom': 3995,\n",
       "                'agentInRoomID0': 3986,\n",
       "                'agentInRoomID1': 3974,\n",
       "                'targetInRoomID0': 4045,\n",
       "                'targetInRoomID1': 3915,\n",
       "                'episodeCount': 7960,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2341,\n",
       "                'targetRoomIndex0': 4045,\n",
       "                'targetRoomIndex1': 3915},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2341,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2341_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -2.0914258444309235,\n",
       "               'std_reward': 1.1159523771}),\n",
       "             (1758,\n",
       "              {'stats': {'sameRoom': 3960,\n",
       "                'agentInRoomID0': 3914,\n",
       "                'agentInRoomID1': 4013,\n",
       "                'targetInRoomID0': 3997,\n",
       "                'targetInRoomID1': 3930,\n",
       "                'episodeCount': 7927,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1758,\n",
       "                'targetRoomIndex0': 3997,\n",
       "                'targetRoomIndex1': 3930},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1758,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1758_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -2.144406539797783,\n",
       "               'std_reward': 1.2082776728}),\n",
       "             (2045,\n",
       "              {'stats': {'sameRoom': 3968,\n",
       "                'agentInRoomID0': 3981,\n",
       "                'agentInRoomID1': 3980,\n",
       "                'targetInRoomID0': 4008,\n",
       "                'targetInRoomID1': 3953,\n",
       "                'episodeCount': 7961,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2045,\n",
       "                'targetRoomIndex0': 4008,\n",
       "                'targetRoomIndex1': 3953},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2045,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2045_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -2.5800197488069534,\n",
       "               'std_reward': 1.6113544376}),\n",
       "             (2303,\n",
       "              {'stats': {'sameRoom': 3959,\n",
       "                'agentInRoomID0': 4018,\n",
       "                'agentInRoomID1': 3969,\n",
       "                'targetInRoomID0': 3952,\n",
       "                'targetInRoomID1': 4035,\n",
       "                'episodeCount': 7987,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2303,\n",
       "                'targetRoomIndex0': 3952,\n",
       "                'targetRoomIndex1': 4035},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2303,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2303_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -3.19019659280777,\n",
       "               'std_reward': 1.81343934}),\n",
       "             (1949,\n",
       "              {'stats': {'sameRoom': 4030,\n",
       "                'agentInRoomID0': 3995,\n",
       "                'agentInRoomID1': 4034,\n",
       "                'targetInRoomID0': 3986,\n",
       "                'targetInRoomID1': 4043,\n",
       "                'episodeCount': 8029,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1949,\n",
       "                'targetRoomIndex0': 3986,\n",
       "                'targetRoomIndex1': 4043},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1949,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1949_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -3.520271790623665,\n",
       "               'std_reward': 1.5489742103}),\n",
       "             (3061,\n",
       "              {'stats': {'sameRoom': 4019,\n",
       "                'agentInRoomID0': 3979,\n",
       "                'agentInRoomID1': 4005,\n",
       "                'targetInRoomID0': 4060,\n",
       "                'targetInRoomID1': 3924,\n",
       "                'episodeCount': 7984,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3061,\n",
       "                'targetRoomIndex0': 4060,\n",
       "                'targetRoomIndex1': 3924},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3061,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3061_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -4.2254842042922975,\n",
       "               'std_reward': 1.352844865}),\n",
       "             (2439,\n",
       "              {'stats': {'sameRoom': 3959,\n",
       "                'agentInRoomID0': 3955,\n",
       "                'agentInRoomID1': 3952,\n",
       "                'targetInRoomID0': 3905,\n",
       "                'targetInRoomID1': 4002,\n",
       "                'episodeCount': 7907,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2439,\n",
       "                'targetRoomIndex0': 3905,\n",
       "                'targetRoomIndex1': 4002},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2439,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2439_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -4.72400890827179,\n",
       "               'std_reward': 1.4234614653}),\n",
       "             (3005,\n",
       "              {'stats': {'sameRoom': 3916,\n",
       "                'agentInRoomID0': 3987,\n",
       "                'agentInRoomID1': 3969,\n",
       "                'targetInRoomID0': 4037,\n",
       "                'targetInRoomID1': 3919,\n",
       "                'episodeCount': 7956,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3005,\n",
       "                'targetRoomIndex0': 4037,\n",
       "                'targetRoomIndex1': 3919},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3005,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3005_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -4.9661017370224,\n",
       "               'std_reward': 1.4995375078}),\n",
       "             (3108,\n",
       "              {'stats': {'sameRoom': 4035,\n",
       "                'agentInRoomID0': 4012,\n",
       "                'agentInRoomID1': 3992,\n",
       "                'targetInRoomID0': 4037,\n",
       "                'targetInRoomID1': 3967,\n",
       "                'episodeCount': 8004,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3108,\n",
       "                'targetRoomIndex0': 4037,\n",
       "                'targetRoomIndex1': 3967},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3108,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3108_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -4.969114241600036,\n",
       "               'std_reward': 1.3920059805}),\n",
       "             (2573,\n",
       "              {'stats': {'sameRoom': 4031,\n",
       "                'agentInRoomID0': 3948,\n",
       "                'agentInRoomID1': 4092,\n",
       "                'targetInRoomID0': 3983,\n",
       "                'targetInRoomID1': 4057,\n",
       "                'episodeCount': 8040,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2573,\n",
       "                'targetRoomIndex0': 3983,\n",
       "                'targetRoomIndex1': 4057},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2573,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2573_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.085814383029938,\n",
       "               'std_reward': 1.4449312606}),\n",
       "             (3734,\n",
       "              {'stats': {'sameRoom': 2096,\n",
       "                'agentInRoomID0': 2106,\n",
       "                'agentInRoomID1': 2172,\n",
       "                'targetInRoomID0': 2064,\n",
       "                'targetInRoomID1': 2214,\n",
       "                'episodeCount': 4278,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3734,\n",
       "                'targetRoomIndex0': 2064,\n",
       "                'targetRoomIndex1': 2214},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3734,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3734_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.1565837478637695,\n",
       "               'std_reward': 3.2094431264}),\n",
       "             (2270,\n",
       "              {'stats': {'sameRoom': 4010,\n",
       "                'agentInRoomID0': 4078,\n",
       "                'agentInRoomID1': 4022,\n",
       "                'targetInRoomID0': 4064,\n",
       "                'targetInRoomID1': 4036,\n",
       "                'episodeCount': 8100,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2270,\n",
       "                'targetRoomIndex0': 4064,\n",
       "                'targetRoomIndex1': 4036},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2270,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2270_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.173721191883087,\n",
       "               'std_reward': 2.77647471}),\n",
       "             (1895,\n",
       "              {'stats': {'sameRoom': 4118,\n",
       "                'agentInRoomID0': 4012,\n",
       "                'agentInRoomID1': 4073,\n",
       "                'targetInRoomID0': 4103,\n",
       "                'targetInRoomID1': 3982,\n",
       "                'episodeCount': 8085,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1895,\n",
       "                'targetRoomIndex0': 4103,\n",
       "                'targetRoomIndex1': 3982},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1895,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1895_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.220113177299499,\n",
       "               'std_reward': 2.3162740238}),\n",
       "             (2958,\n",
       "              {'stats': {'sameRoom': 4000,\n",
       "                'agentInRoomID0': 4020,\n",
       "                'agentInRoomID1': 3982,\n",
       "                'targetInRoomID0': 4068,\n",
       "                'targetInRoomID1': 3934,\n",
       "                'episodeCount': 8002,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2958,\n",
       "                'targetRoomIndex0': 4068,\n",
       "                'targetRoomIndex1': 3934},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2958,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2958_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.3323588466644285,\n",
       "               'std_reward': 1.7358413277}),\n",
       "             (2503,\n",
       "              {'stats': {'sameRoom': 3939,\n",
       "                'agentInRoomID0': 3946,\n",
       "                'agentInRoomID1': 4050,\n",
       "                'targetInRoomID0': 4049,\n",
       "                'targetInRoomID1': 3947,\n",
       "                'episodeCount': 7996,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2503,\n",
       "                'targetRoomIndex0': 4049,\n",
       "                'targetRoomIndex1': 3947},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2503,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2503_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.33636382818222,\n",
       "               'std_reward': 1.448451978}),\n",
       "             (3295,\n",
       "              {'stats': {'sameRoom': 2087,\n",
       "                'agentInRoomID0': 2136,\n",
       "                'agentInRoomID1': 2126,\n",
       "                'targetInRoomID0': 2133,\n",
       "                'targetInRoomID1': 2129,\n",
       "                'episodeCount': 4262,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3295,\n",
       "                'targetRoomIndex0': 2133,\n",
       "                'targetRoomIndex1': 2129},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3295,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3295_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.6833857369422915,\n",
       "               'std_reward': 2.9069578963}),\n",
       "             (1751,\n",
       "              {'stats': {'sameRoom': 4059,\n",
       "                'agentInRoomID0': 4011,\n",
       "                'agentInRoomID1': 4055,\n",
       "                'targetInRoomID0': 4048,\n",
       "                'targetInRoomID1': 4018,\n",
       "                'episodeCount': 8066,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1751,\n",
       "                'targetRoomIndex0': 4048,\n",
       "                'targetRoomIndex1': 4018},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1751,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1751_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -5.713958233594894,\n",
       "               'std_reward': 2.7929704477}),\n",
       "             (2323,\n",
       "              {'stats': {'sameRoom': 4024,\n",
       "                'agentInRoomID0': 3989,\n",
       "                'agentInRoomID1': 4118,\n",
       "                'targetInRoomID0': 4068,\n",
       "                'targetInRoomID1': 4039,\n",
       "                'episodeCount': 8107,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2323,\n",
       "                'targetRoomIndex0': 4068,\n",
       "                'targetRoomIndex1': 4039},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2323,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2323_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.035322086811066,\n",
       "               'std_reward': 2.2855044489}),\n",
       "             (2518,\n",
       "              {'stats': {'sameRoom': 4132,\n",
       "                'agentInRoomID0': 3984,\n",
       "                'agentInRoomID1': 4068,\n",
       "                'targetInRoomID0': 4102,\n",
       "                'targetInRoomID1': 3950,\n",
       "                'episodeCount': 8052,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2518,\n",
       "                'targetRoomIndex0': 4102,\n",
       "                'targetRoomIndex1': 3950},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2518,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2518_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.228882830142975,\n",
       "               'std_reward': 1.9543649102}),\n",
       "             (3751,\n",
       "              {'stats': {'sameRoom': 2160,\n",
       "                'agentInRoomID0': 2239,\n",
       "                'agentInRoomID1': 2118,\n",
       "                'targetInRoomID0': 2170,\n",
       "                'targetInRoomID1': 2187,\n",
       "                'episodeCount': 4357,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3751,\n",
       "                'targetRoomIndex0': 2170,\n",
       "                'targetRoomIndex1': 2187},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3751,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3751_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.540849951505661,\n",
       "               'std_reward': 3.1551079752}),\n",
       "             (3580,\n",
       "              {'stats': {'sameRoom': 2142,\n",
       "                'agentInRoomID0': 2141,\n",
       "                'agentInRoomID1': 2226,\n",
       "                'targetInRoomID0': 2166,\n",
       "                'targetInRoomID1': 2201,\n",
       "                'episodeCount': 4367,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3580,\n",
       "                'targetRoomIndex0': 2166,\n",
       "                'targetRoomIndex1': 2201},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3580,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3580_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.617854777574539,\n",
       "               'std_reward': 2.9260831564}),\n",
       "             (1891,\n",
       "              {'stats': {'sameRoom': 4099,\n",
       "                'agentInRoomID0': 4054,\n",
       "                'agentInRoomID1': 4166,\n",
       "                'targetInRoomID0': 4043,\n",
       "                'targetInRoomID1': 4177,\n",
       "                'episodeCount': 8220,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1891,\n",
       "                'targetRoomIndex0': 4043,\n",
       "                'targetRoomIndex1': 4177},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1891,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1891_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.6373238384723665,\n",
       "               'std_reward': 2.9947320805}),\n",
       "             (3036,\n",
       "              {'stats': {'sameRoom': 3991,\n",
       "                'agentInRoomID0': 4074,\n",
       "                'agentInRoomID1': 4032,\n",
       "                'targetInRoomID0': 4085,\n",
       "                'targetInRoomID1': 4021,\n",
       "                'episodeCount': 8106,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3036,\n",
       "                'targetRoomIndex0': 4085,\n",
       "                'targetRoomIndex1': 4021},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3036,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3036_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.796697905063629,\n",
       "               'std_reward': 2.1700835266}),\n",
       "             (2352,\n",
       "              {'stats': {'sameRoom': 4152,\n",
       "                'agentInRoomID0': 4063,\n",
       "                'agentInRoomID1': 4166,\n",
       "                'targetInRoomID0': 4168,\n",
       "                'targetInRoomID1': 4061,\n",
       "                'episodeCount': 8229,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2352,\n",
       "                'targetRoomIndex0': 4168,\n",
       "                'targetRoomIndex1': 4061},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2352,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2352_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -6.8647337555885315,\n",
       "               'std_reward': 2.4456860158}),\n",
       "             (1808,\n",
       "              {'stats': {'sameRoom': 4035,\n",
       "                'agentInRoomID0': 4048,\n",
       "                'agentInRoomID1': 4062,\n",
       "                'targetInRoomID0': 4073,\n",
       "                'targetInRoomID1': 4037,\n",
       "                'episodeCount': 8110,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1808,\n",
       "                'targetRoomIndex0': 4073,\n",
       "                'targetRoomIndex1': 4037},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1808,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1808_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.090488557815552,\n",
       "               'std_reward': 2.0527802777}),\n",
       "             (2996,\n",
       "              {'stats': {'sameRoom': 3952,\n",
       "                'agentInRoomID0': 4010,\n",
       "                'agentInRoomID1': 4064,\n",
       "                'targetInRoomID0': 4084,\n",
       "                'targetInRoomID1': 3990,\n",
       "                'episodeCount': 8074,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2996,\n",
       "                'targetRoomIndex0': 4084,\n",
       "                'targetRoomIndex1': 3990},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2996,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2996_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.131565461158752,\n",
       "               'std_reward': 2.1836071636}),\n",
       "             (3087,\n",
       "              {'stats': {'sameRoom': 4099,\n",
       "                'agentInRoomID0': 4083,\n",
       "                'agentInRoomID1': 4074,\n",
       "                'targetInRoomID0': 4099,\n",
       "                'targetInRoomID1': 4058,\n",
       "                'episodeCount': 8157,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3087,\n",
       "                'targetRoomIndex0': 4099,\n",
       "                'targetRoomIndex1': 4058},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3087,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3087_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.49688179731369,\n",
       "               'std_reward': 2.4670861064}),\n",
       "             (3134,\n",
       "              {'stats': {'sameRoom': 4109,\n",
       "                'agentInRoomID0': 4074,\n",
       "                'agentInRoomID1': 4089,\n",
       "                'targetInRoomID0': 4138,\n",
       "                'targetInRoomID1': 4025,\n",
       "                'episodeCount': 8163,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3134,\n",
       "                'targetRoomIndex0': 4138,\n",
       "                'targetRoomIndex1': 4025},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3134,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3134_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.7119170093536376,\n",
       "               'std_reward': 3.1314073495}),\n",
       "             (3788,\n",
       "              {'stats': {'sameRoom': 2150,\n",
       "                'agentInRoomID0': 2167,\n",
       "                'agentInRoomID1': 2186,\n",
       "                'targetInRoomID0': 2132,\n",
       "                'targetInRoomID1': 2221,\n",
       "                'episodeCount': 4353,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3788,\n",
       "                'targetRoomIndex0': 2132,\n",
       "                'targetRoomIndex1': 2221},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3788,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3788_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.759228980541229,\n",
       "               'std_reward': 3.4480657145}),\n",
       "             (3876,\n",
       "              {'stats': {'sameRoom': 2155,\n",
       "                'agentInRoomID0': 2107,\n",
       "                'agentInRoomID1': 2110,\n",
       "                'targetInRoomID0': 2097,\n",
       "                'targetInRoomID1': 2120,\n",
       "                'episodeCount': 4217,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3876,\n",
       "                'targetRoomIndex0': 2097,\n",
       "                'targetRoomIndex1': 2120},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3876,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3876_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.901673955917358,\n",
       "               'std_reward': 2.3425366847}),\n",
       "             (2979,\n",
       "              {'stats': {'sameRoom': 4231,\n",
       "                'agentInRoomID0': 4167,\n",
       "                'agentInRoomID1': 4033,\n",
       "                'targetInRoomID0': 4214,\n",
       "                'targetInRoomID1': 3986,\n",
       "                'episodeCount': 8200,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2979,\n",
       "                'targetRoomIndex0': 4214,\n",
       "                'targetRoomIndex1': 3986},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2979,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2979_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -7.95310950756073,\n",
       "               'std_reward': 2.4879076405}),\n",
       "             (1842,\n",
       "              {'stats': {'sameRoom': 4020,\n",
       "                'agentInRoomID0': 3981,\n",
       "                'agentInRoomID1': 4191,\n",
       "                'targetInRoomID0': 4075,\n",
       "                'targetInRoomID1': 4097,\n",
       "                'episodeCount': 8172,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1842,\n",
       "                'targetRoomIndex0': 4075,\n",
       "                'targetRoomIndex1': 4097},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1842,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1842_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.065249834060669,\n",
       "               'std_reward': 2.8970587234}),\n",
       "             (1968,\n",
       "              {'stats': {'sameRoom': 4139,\n",
       "                'agentInRoomID0': 4066,\n",
       "                'agentInRoomID1': 4197,\n",
       "                'targetInRoomID0': 4180,\n",
       "                'targetInRoomID1': 4083,\n",
       "                'episodeCount': 8263,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1968,\n",
       "                'targetRoomIndex0': 4180,\n",
       "                'targetRoomIndex1': 4083},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1968,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1968_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.380782554149627,\n",
       "               'std_reward': 2.4572232257}),\n",
       "             (3548,\n",
       "              {'stats': {'sameRoom': 2222,\n",
       "                'agentInRoomID0': 2160,\n",
       "                'agentInRoomID1': 2226,\n",
       "                'targetInRoomID0': 2184,\n",
       "                'targetInRoomID1': 2202,\n",
       "                'episodeCount': 4386,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3548,\n",
       "                'targetRoomIndex0': 2184,\n",
       "                'targetRoomIndex1': 2202},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3548,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3548_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.783655767440797,\n",
       "               'std_reward': 4.1630454618}),\n",
       "             (4204,\n",
       "              {'stats': {'sameRoom': 2226,\n",
       "                'agentInRoomID0': 2103,\n",
       "                'agentInRoomID1': 2192,\n",
       "                'targetInRoomID0': 2156,\n",
       "                'targetInRoomID1': 2139,\n",
       "                'episodeCount': 4295,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4204,\n",
       "                'targetRoomIndex0': 2156,\n",
       "                'targetRoomIndex1': 2139},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4204,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4204_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.878439474105836,\n",
       "               'std_reward': 2.6881100685}),\n",
       "             (3091,\n",
       "              {'stats': {'sameRoom': 4112,\n",
       "                'agentInRoomID0': 4119,\n",
       "                'agentInRoomID1': 4057,\n",
       "                'targetInRoomID0': 4051,\n",
       "                'targetInRoomID1': 4125,\n",
       "                'episodeCount': 8176,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3091,\n",
       "                'targetRoomIndex0': 4051,\n",
       "                'targetRoomIndex1': 4125},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3091,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3091_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.941712455749512,\n",
       "               'std_reward': 2.8711034447}),\n",
       "             (2032,\n",
       "              {'stats': {'sameRoom': 4146,\n",
       "                'agentInRoomID0': 4111,\n",
       "                'agentInRoomID1': 4140,\n",
       "                'targetInRoomID0': 4032,\n",
       "                'targetInRoomID1': 4219,\n",
       "                'episodeCount': 8251,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2032,\n",
       "                'targetRoomIndex0': 4032,\n",
       "                'targetRoomIndex1': 4219},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 2032,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2032_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -8.98768949508667,\n",
       "               'std_reward': 2.5736980385}),\n",
       "             (4110,\n",
       "              {'stats': {'sameRoom': 2196,\n",
       "                'agentInRoomID0': 2178,\n",
       "                'agentInRoomID1': 2157,\n",
       "                'targetInRoomID0': 2189,\n",
       "                'targetInRoomID1': 2146,\n",
       "                'episodeCount': 4335,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4110,\n",
       "                'targetRoomIndex0': 2189,\n",
       "                'targetRoomIndex1': 2146},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4110,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4110_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -9.473069105148316,\n",
       "               'std_reward': 3.3142861033}),\n",
       "             (1793,\n",
       "              {'stats': {'sameRoom': 4113,\n",
       "                'agentInRoomID0': 4050,\n",
       "                'agentInRoomID1': 4132,\n",
       "                'targetInRoomID0': 4153,\n",
       "                'targetInRoomID1': 4029,\n",
       "                'episodeCount': 8182,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1793,\n",
       "                'targetRoomIndex0': 4153,\n",
       "                'targetRoomIndex1': 4029},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1793,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1793_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -9.593874406814574,\n",
       "               'std_reward': 2.785956571}),\n",
       "             (4015,\n",
       "              {'stats': {'sameRoom': 2109,\n",
       "                'agentInRoomID0': 2170,\n",
       "                'agentInRoomID1': 2150,\n",
       "                'targetInRoomID0': 2155,\n",
       "                'targetInRoomID1': 2165,\n",
       "                'episodeCount': 4320,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4015,\n",
       "                'targetRoomIndex0': 2155,\n",
       "                'targetRoomIndex1': 2165},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4015,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4015_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -10.681053833961487,\n",
       "               'std_reward': 4.0145061528}),\n",
       "             (3765,\n",
       "              {'stats': {'sameRoom': 2221,\n",
       "                'agentInRoomID0': 2232,\n",
       "                'agentInRoomID1': 2188,\n",
       "                'targetInRoomID0': 2253,\n",
       "                'targetInRoomID1': 2167,\n",
       "                'episodeCount': 4420,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3765,\n",
       "                'targetRoomIndex0': 2253,\n",
       "                'targetRoomIndex1': 2167},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3765,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3765_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -11.228681845664978,\n",
       "               'std_reward': 5.0172288313}),\n",
       "             (2560,\n",
       "              {'stats': {'sameRoom': 4074,\n",
       "                'agentInRoomID0': 4150,\n",
       "                'agentInRoomID1': 4071,\n",
       "                'targetInRoomID0': 4069,\n",
       "                'targetInRoomID1': 4152,\n",
       "                'episodeCount': 8221,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2560,\n",
       "                'targetRoomIndex0': 4069,\n",
       "                'targetRoomIndex1': 4152},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2560,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2560_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -12.332514042854308,\n",
       "               'std_reward': 2.3453941364}),\n",
       "             (3717,\n",
       "              {'stats': {'sameRoom': 2251,\n",
       "                'agentInRoomID0': 2226,\n",
       "                'agentInRoomID1': 2242,\n",
       "                'targetInRoomID0': 2257,\n",
       "                'targetInRoomID1': 2211,\n",
       "                'episodeCount': 4468,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3717,\n",
       "                'targetRoomIndex0': 2257,\n",
       "                'targetRoomIndex1': 2211},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3717,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3717_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -12.461356787681579,\n",
       "               'std_reward': 6.14288682}),\n",
       "             (4654,\n",
       "              {'stats': {'sameRoom': 984,\n",
       "                'agentInRoomID0': 977,\n",
       "                'agentInRoomID1': 993,\n",
       "                'targetInRoomID0': 1013,\n",
       "                'targetInRoomID1': 957,\n",
       "                'episodeCount': 1970,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4654,\n",
       "                'targetRoomIndex0': 1013,\n",
       "                'targetRoomIndex1': 957},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 4654,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4654_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -13.401860277652741,\n",
       "               'std_reward': 9.1469243728}),\n",
       "             (3923,\n",
       "              {'stats': {'sameRoom': 2146,\n",
       "                'agentInRoomID0': 2156,\n",
       "                'agentInRoomID1': 2220,\n",
       "                'targetInRoomID0': 2168,\n",
       "                'targetInRoomID1': 2208,\n",
       "                'episodeCount': 4376,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3923,\n",
       "                'targetRoomIndex0': 2168,\n",
       "                'targetRoomIndex1': 2208},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3923,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3923_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -13.477673726081848,\n",
       "               'std_reward': 4.9649994547}),\n",
       "             (3572,\n",
       "              {'stats': {'sameRoom': 2282,\n",
       "                'agentInRoomID0': 2245,\n",
       "                'agentInRoomID1': 2226,\n",
       "                'targetInRoomID0': 2234,\n",
       "                'targetInRoomID1': 2237,\n",
       "                'episodeCount': 4471,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3572,\n",
       "                'targetRoomIndex0': 2234,\n",
       "                'targetRoomIndex1': 2237},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3572,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3572_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -13.92630443572998,\n",
       "               'std_reward': 5.9725294312}),\n",
       "             (1706,\n",
       "              {'stats': {'sameRoom': 4093,\n",
       "                'agentInRoomID0': 4114,\n",
       "                'agentInRoomID1': 4154,\n",
       "                'targetInRoomID0': 4157,\n",
       "                'targetInRoomID1': 4111,\n",
       "                'episodeCount': 8268,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1706,\n",
       "                'targetRoomIndex0': 4157,\n",
       "                'targetRoomIndex1': 4111},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1706,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1706_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -14.338176288604735,\n",
       "               'std_reward': 2.2934369944}),\n",
       "             (3632,\n",
       "              {'stats': {'sameRoom': 2263,\n",
       "                'agentInRoomID0': 2220,\n",
       "                'agentInRoomID1': 2286,\n",
       "                'targetInRoomID0': 2231,\n",
       "                'targetInRoomID1': 2275,\n",
       "                'episodeCount': 4506,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3632,\n",
       "                'targetRoomIndex0': 2231,\n",
       "                'targetRoomIndex1': 2275},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3632,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3632_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -14.371629204750061,\n",
       "               'std_reward': 4.7891357184}),\n",
       "             (4479,\n",
       "              {'stats': {'sameRoom': 2219,\n",
       "                'agentInRoomID0': 2190,\n",
       "                'agentInRoomID1': 2242,\n",
       "                'targetInRoomID0': 2233,\n",
       "                'targetInRoomID1': 2199,\n",
       "                'episodeCount': 4432,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4479,\n",
       "                'targetRoomIndex0': 2233,\n",
       "                'targetRoomIndex1': 2199},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4479,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4479_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -14.520918998718262,\n",
       "               'std_reward': 5.0042705259}),\n",
       "             (4499,\n",
       "              {'stats': {'sameRoom': 2169,\n",
       "                'agentInRoomID0': 2157,\n",
       "                'agentInRoomID1': 2240,\n",
       "                'targetInRoomID0': 2197,\n",
       "                'targetInRoomID1': 2200,\n",
       "                'episodeCount': 4397,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4499,\n",
       "                'targetRoomIndex0': 2197,\n",
       "                'targetRoomIndex1': 2200},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4499,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4499_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -14.750628509521484,\n",
       "               'std_reward': 6.1413011727}),\n",
       "             (4342,\n",
       "              {'stats': {'sameRoom': 2223,\n",
       "                'agentInRoomID0': 2248,\n",
       "                'agentInRoomID1': 2188,\n",
       "                'targetInRoomID0': 2251,\n",
       "                'targetInRoomID1': 2185,\n",
       "                'episodeCount': 4436,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4342,\n",
       "                'targetRoomIndex0': 2251,\n",
       "                'targetRoomIndex1': 2185},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4342,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4342_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -14.930417642593383,\n",
       "               'std_reward': 5.5747972701}),\n",
       "             (1770,\n",
       "              {'stats': {'sameRoom': 4162,\n",
       "                'agentInRoomID0': 4162,\n",
       "                'agentInRoomID1': 4094,\n",
       "                'targetInRoomID0': 4190,\n",
       "                'targetInRoomID1': 4066,\n",
       "                'episodeCount': 8256,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1770,\n",
       "                'targetRoomIndex0': 4190,\n",
       "                'targetRoomIndex1': 4066},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1770,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1770_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -15.078089318275453,\n",
       "               'std_reward': 2.6065295051}),\n",
       "             (3035,\n",
       "              {'stats': {'sameRoom': 4203,\n",
       "                'agentInRoomID0': 4118,\n",
       "                'agentInRoomID1': 4185,\n",
       "                'targetInRoomID0': 4128,\n",
       "                'targetInRoomID1': 4175,\n",
       "                'episodeCount': 8303,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3035,\n",
       "                'targetRoomIndex0': 4128,\n",
       "                'targetRoomIndex1': 4175},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 3035,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3035_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -16.224553451538085,\n",
       "               'std_reward': 2.3877380758}),\n",
       "             (4244,\n",
       "              {'stats': {'sameRoom': 2213,\n",
       "                'agentInRoomID0': 2252,\n",
       "                'agentInRoomID1': 2205,\n",
       "                'targetInRoomID0': 2260,\n",
       "                'targetInRoomID1': 2197,\n",
       "                'episodeCount': 4457,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4244,\n",
       "                'targetRoomIndex0': 2260,\n",
       "                'targetRoomIndex1': 2197},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4244,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4244_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -16.25365110397339,\n",
       "               'std_reward': 5.4802840722}),\n",
       "             (1928,\n",
       "              {'stats': {'sameRoom': 4190,\n",
       "                'agentInRoomID0': 4162,\n",
       "                'agentInRoomID1': 4157,\n",
       "                'targetInRoomID0': 4177,\n",
       "                'targetInRoomID1': 4142,\n",
       "                'episodeCount': 8319,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 1928,\n",
       "                'targetRoomIndex0': 4177,\n",
       "                'targetRoomIndex1': 4142},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 1928,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\1928_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -17.68716954231262,\n",
       "               'std_reward': 2.3317615386}),\n",
       "             (2699,\n",
       "              {'stats': {'sameRoom': 4010,\n",
       "                'agentInRoomID0': 4104,\n",
       "                'agentInRoomID1': 4124,\n",
       "                'targetInRoomID0': 4162,\n",
       "                'targetInRoomID1': 4066,\n",
       "                'episodeCount': 8228,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2699,\n",
       "                'targetRoomIndex0': 4162,\n",
       "                'targetRoomIndex1': 4066},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2699,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2699_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -18.487487239837648,\n",
       "               'std_reward': 2.6236131236}),\n",
       "             (2744,\n",
       "              {'stats': {'sameRoom': 4190,\n",
       "                'agentInRoomID0': 4251,\n",
       "                'agentInRoomID1': 4050,\n",
       "                'targetInRoomID0': 4158,\n",
       "                'targetInRoomID1': 4143,\n",
       "                'episodeCount': 8301,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 2744,\n",
       "                'targetRoomIndex0': 4158,\n",
       "                'targetRoomIndex1': 4143},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 2744,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\2744_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -18.58765935897827,\n",
       "               'std_reward': 2.1645094484}),\n",
       "             (4209,\n",
       "              {'stats': {'sameRoom': 2285,\n",
       "                'agentInRoomID0': 2270,\n",
       "                'agentInRoomID1': 2285,\n",
       "                'targetInRoomID0': 2244,\n",
       "                'targetInRoomID1': 2311,\n",
       "                'episodeCount': 4555,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4209,\n",
       "                'targetRoomIndex0': 2244,\n",
       "                'targetRoomIndex1': 2311},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4209,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4209_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -18.660397548675537,\n",
       "               'std_reward': 4.5782355758}),\n",
       "             (3378,\n",
       "              {'stats': {'sameRoom': 2304,\n",
       "                'agentInRoomID0': 2303,\n",
       "                'agentInRoomID1': 2259,\n",
       "                'targetInRoomID0': 2201,\n",
       "                'targetInRoomID1': 2361,\n",
       "                'episodeCount': 4562,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3378,\n",
       "                'targetRoomIndex0': 2201,\n",
       "                'targetRoomIndex1': 2361},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3378,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3378_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -19.00839376926422,\n",
       "               'std_reward': 8.0900514105}),\n",
       "             (5316,\n",
       "              {'stats': {'sameRoom': 977,\n",
       "                'agentInRoomID0': 1001,\n",
       "                'agentInRoomID1': 972,\n",
       "                'targetInRoomID0': 1001,\n",
       "                'targetInRoomID1': 972,\n",
       "                'episodeCount': 1973,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5316,\n",
       "                'targetRoomIndex0': 1001,\n",
       "                'targetRoomIndex1': 972},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5316,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5316_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -19.23954623222351,\n",
       "               'std_reward': 6.4482566516}),\n",
       "             (5413,\n",
       "              {'stats': {'sameRoom': 1006,\n",
       "                'agentInRoomID0': 1002,\n",
       "                'agentInRoomID1': 1011,\n",
       "                'targetInRoomID0': 1031,\n",
       "                'targetInRoomID1': 982,\n",
       "                'episodeCount': 2013,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5413,\n",
       "                'targetRoomIndex0': 1031,\n",
       "                'targetRoomIndex1': 982},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5413,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5413_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -21.518326692581176,\n",
       "               'std_reward': 6.5706475019}),\n",
       "             (4289,\n",
       "              {'stats': {'sameRoom': 2219,\n",
       "                'agentInRoomID0': 2260,\n",
       "                'agentInRoomID1': 2287,\n",
       "                'targetInRoomID0': 2270,\n",
       "                'targetInRoomID1': 2277,\n",
       "                'episodeCount': 4547,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4289,\n",
       "                'targetRoomIndex0': 2270,\n",
       "                'targetRoomIndex1': 2277},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4289,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4289_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -22.52404811859131,\n",
       "               'std_reward': 5.4619264478}),\n",
       "             (4192,\n",
       "              {'stats': {'sameRoom': 2311,\n",
       "                'agentInRoomID0': 2288,\n",
       "                'agentInRoomID1': 2301,\n",
       "                'targetInRoomID0': 2254,\n",
       "                'targetInRoomID1': 2335,\n",
       "                'episodeCount': 4589,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4192,\n",
       "                'targetRoomIndex0': 2254,\n",
       "                'targetRoomIndex1': 2335},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4192,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4192_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -24.478093423843383,\n",
       "               'std_reward': 5.9840369997}),\n",
       "             (5430,\n",
       "              {'stats': {'sameRoom': 990,\n",
       "                'agentInRoomID0': 1000,\n",
       "                'agentInRoomID1': 983,\n",
       "                'targetInRoomID0': 1015,\n",
       "                'targetInRoomID1': 968,\n",
       "                'episodeCount': 1983,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5430,\n",
       "                'targetRoomIndex0': 1015,\n",
       "                'targetRoomIndex1': 968},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5430,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5430_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -25.41454517364502,\n",
       "               'std_reward': 10.3733135567}),\n",
       "             (5315,\n",
       "              {'stats': {'sameRoom': 1083,\n",
       "                'agentInRoomID0': 1075,\n",
       "                'agentInRoomID1': 1044,\n",
       "                'targetInRoomID0': 1039,\n",
       "                'targetInRoomID1': 1080,\n",
       "                'episodeCount': 2119,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5315,\n",
       "                'targetRoomIndex0': 1039,\n",
       "                'targetRoomIndex1': 1080},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5315,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5315_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -25.671231307983398,\n",
       "               'std_reward': 8.2806184903}),\n",
       "             (5941,\n",
       "              {'stats': {'sameRoom': 1029,\n",
       "                'agentInRoomID0': 1109,\n",
       "                'agentInRoomID1': 1006,\n",
       "                'targetInRoomID0': 1065,\n",
       "                'targetInRoomID1': 1050,\n",
       "                'episodeCount': 2115,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5941,\n",
       "                'targetRoomIndex0': 1065,\n",
       "                'targetRoomIndex1': 1050},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5941,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5941_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -26.92561978340149,\n",
       "               'std_reward': 9.361514925}),\n",
       "             (5102,\n",
       "              {'stats': {'sameRoom': 1087,\n",
       "                'agentInRoomID0': 1071,\n",
       "                'agentInRoomID1': 1151,\n",
       "                'targetInRoomID0': 1098,\n",
       "                'targetInRoomID1': 1124,\n",
       "                'episodeCount': 2222,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5102,\n",
       "                'targetRoomIndex0': 1098,\n",
       "                'targetRoomIndex1': 1124},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5102,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5102_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -26.976541457176207,\n",
       "               'std_reward': 15.1643022519}),\n",
       "             (5168,\n",
       "              {'stats': {'sameRoom': 1094,\n",
       "                'agentInRoomID0': 1109,\n",
       "                'agentInRoomID1': 1109,\n",
       "                'targetInRoomID0': 1139,\n",
       "                'targetInRoomID1': 1079,\n",
       "                'episodeCount': 2218,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5168,\n",
       "                'targetRoomIndex0': 1139,\n",
       "                'targetRoomIndex1': 1079},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5168,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5168_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -27.515574264526368,\n",
       "               'std_reward': 13.2334451625}),\n",
       "             (3579,\n",
       "              {'stats': {'sameRoom': 2426,\n",
       "                'agentInRoomID0': 2389,\n",
       "                'agentInRoomID1': 2329,\n",
       "                'targetInRoomID0': 2367,\n",
       "                'targetInRoomID1': 2351,\n",
       "                'episodeCount': 4718,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3579,\n",
       "                'targetRoomIndex0': 2367,\n",
       "                'targetRoomIndex1': 2351},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3579,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3579_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -28.150719966888428,\n",
       "               'std_reward': 5.1996008453}),\n",
       "             (5330,\n",
       "              {'stats': {'sameRoom': 1075,\n",
       "                'agentInRoomID0': 1100,\n",
       "                'agentInRoomID1': 1043,\n",
       "                'targetInRoomID0': 1110,\n",
       "                'targetInRoomID1': 1033,\n",
       "                'episodeCount': 2143,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5330,\n",
       "                'targetRoomIndex0': 1110,\n",
       "                'targetRoomIndex1': 1033},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5330,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5330_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -29.087657823562623,\n",
       "               'std_reward': 10.257518623}),\n",
       "             (5662,\n",
       "              {'stats': {'sameRoom': 1068,\n",
       "                'agentInRoomID0': 1082,\n",
       "                'agentInRoomID1': 1123,\n",
       "                'targetInRoomID0': 1105,\n",
       "                'targetInRoomID1': 1100,\n",
       "                'episodeCount': 2205,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5662,\n",
       "                'targetRoomIndex0': 1105,\n",
       "                'targetRoomIndex1': 1100},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5662,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5662_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -29.131253442764283,\n",
       "               'std_reward': 10.0296478338}),\n",
       "             (5043,\n",
       "              {'stats': {'sameRoom': 1075,\n",
       "                'agentInRoomID0': 1105,\n",
       "                'agentInRoomID1': 1147,\n",
       "                'targetInRoomID0': 1144,\n",
       "                'targetInRoomID1': 1108,\n",
       "                'episodeCount': 2252,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5043,\n",
       "                'targetRoomIndex0': 1144,\n",
       "                'targetRoomIndex1': 1108},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5043,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5043_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -30.02226529121399,\n",
       "               'std_reward': 13.237603536}),\n",
       "             (5027,\n",
       "              {'stats': {'sameRoom': 1140,\n",
       "                'agentInRoomID0': 1119,\n",
       "                'agentInRoomID1': 1173,\n",
       "                'targetInRoomID0': 1123,\n",
       "                'targetInRoomID1': 1169,\n",
       "                'episodeCount': 2292,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5027,\n",
       "                'targetRoomIndex0': 1123,\n",
       "                'targetRoomIndex1': 1169},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5027,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5027_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -30.064640321731567,\n",
       "               'std_reward': 12.6296749311}),\n",
       "             (5956,\n",
       "              {'stats': {'sameRoom': 1116,\n",
       "                'agentInRoomID0': 1100,\n",
       "                'agentInRoomID1': 1123,\n",
       "                'targetInRoomID0': 1115,\n",
       "                'targetInRoomID1': 1108,\n",
       "                'episodeCount': 2223,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5956,\n",
       "                'targetRoomIndex0': 1115,\n",
       "                'targetRoomIndex1': 1108},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5956,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5956_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -30.474788904190063,\n",
       "               'std_reward': 10.7750054166}),\n",
       "             (5246,\n",
       "              {'stats': {'sameRoom': 1083,\n",
       "                'agentInRoomID0': 1103,\n",
       "                'agentInRoomID1': 1109,\n",
       "                'targetInRoomID0': 1086,\n",
       "                'targetInRoomID1': 1126,\n",
       "                'episodeCount': 2212,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5246,\n",
       "                'targetRoomIndex0': 1086,\n",
       "                'targetRoomIndex1': 1126},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5246,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5246_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -30.735101585388183,\n",
       "               'std_reward': 16.1636796948}),\n",
       "             (3192,\n",
       "              {'stats': {'sameRoom': 2313,\n",
       "                'agentInRoomID0': 2209,\n",
       "                'agentInRoomID1': 2347,\n",
       "                'targetInRoomID0': 2288,\n",
       "                'targetInRoomID1': 2268,\n",
       "                'episodeCount': 4556,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3192,\n",
       "                'targetRoomIndex0': 2288,\n",
       "                'targetRoomIndex1': 2268},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3192,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3192_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -31.17646614074707,\n",
       "               'std_reward': 4.784492968}),\n",
       "             (3818,\n",
       "              {'stats': {'sameRoom': 2421,\n",
       "                'agentInRoomID0': 2324,\n",
       "                'agentInRoomID1': 2367,\n",
       "                'targetInRoomID0': 2310,\n",
       "                'targetInRoomID1': 2381,\n",
       "                'episodeCount': 4691,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3818,\n",
       "                'targetRoomIndex0': 2310,\n",
       "                'targetRoomIndex1': 2381},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3818,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3818_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -31.198433990478517,\n",
       "               'std_reward': 5.3450141914}),\n",
       "             (3243,\n",
       "              {'stats': {'sameRoom': 2240,\n",
       "                'agentInRoomID0': 2225,\n",
       "                'agentInRoomID1': 2317,\n",
       "                'targetInRoomID0': 2311,\n",
       "                'targetInRoomID1': 2231,\n",
       "                'episodeCount': 4542,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3243,\n",
       "                'targetRoomIndex0': 2311,\n",
       "                'targetRoomIndex1': 2231},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3243,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3243_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -32.06144481658936,\n",
       "               'std_reward': 5.3480248725}),\n",
       "             (5266,\n",
       "              {'stats': {'sameRoom': 1112,\n",
       "                'agentInRoomID0': 1153,\n",
       "                'agentInRoomID1': 1109,\n",
       "                'targetInRoomID0': 1117,\n",
       "                'targetInRoomID1': 1145,\n",
       "                'episodeCount': 2262,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5266,\n",
       "                'targetRoomIndex0': 1117,\n",
       "                'targetRoomIndex1': 1145},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5266,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5266_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -32.2620006942749,\n",
       "               'std_reward': 14.7866104193}),\n",
       "             (3657,\n",
       "              {'stats': {'sameRoom': 2284,\n",
       "                'agentInRoomID0': 2347,\n",
       "                'agentInRoomID1': 2254,\n",
       "                'targetInRoomID0': 2280,\n",
       "                'targetInRoomID1': 2321,\n",
       "                'episodeCount': 4601,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3657,\n",
       "                'targetRoomIndex0': 2280,\n",
       "                'targetRoomIndex1': 2321},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3657,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3657_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -33.251210384368896,\n",
       "               'std_reward': 4.8671767058}),\n",
       "             (4571,\n",
       "              {'stats': {'sameRoom': 2308,\n",
       "                'agentInRoomID0': 2265,\n",
       "                'agentInRoomID1': 2366,\n",
       "                'targetInRoomID0': 2340,\n",
       "                'targetInRoomID1': 2291,\n",
       "                'episodeCount': 4631,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4571,\n",
       "                'targetRoomIndex0': 2340,\n",
       "                'targetRoomIndex1': 2291},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4571,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4571_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -34.90654130935669,\n",
       "               'std_reward': 5.5251181422}),\n",
       "             (5136,\n",
       "              {'stats': {'sameRoom': 1155,\n",
       "                'agentInRoomID0': 1135,\n",
       "                'agentInRoomID1': 1149,\n",
       "                'targetInRoomID0': 1082,\n",
       "                'targetInRoomID1': 1202,\n",
       "                'episodeCount': 2284,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5136,\n",
       "                'targetRoomIndex0': 1082,\n",
       "                'targetRoomIndex1': 1202},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5136,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5136_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -35.90916366577149,\n",
       "               'std_reward': 11.6725171548}),\n",
       "             (3272,\n",
       "              {'stats': {'sameRoom': 2184,\n",
       "                'agentInRoomID0': 2278,\n",
       "                'agentInRoomID1': 2197,\n",
       "                'targetInRoomID0': 2287,\n",
       "                'targetInRoomID1': 2188,\n",
       "                'episodeCount': 4475,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 3272,\n",
       "                'targetRoomIndex0': 2287,\n",
       "                'targetRoomIndex1': 2188},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 3272,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\3272_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -36.14507192611694,\n",
       "               'std_reward': 4.925585236}),\n",
       "             (5617,\n",
       "              {'stats': {'sameRoom': 1168,\n",
       "                'agentInRoomID0': 1147,\n",
       "                'agentInRoomID1': 1155,\n",
       "                'targetInRoomID0': 1173,\n",
       "                'targetInRoomID1': 1129,\n",
       "                'episodeCount': 2302,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5617,\n",
       "                'targetRoomIndex0': 1173,\n",
       "                'targetRoomIndex1': 1129},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5617,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5617_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -37.12368366241455,\n",
       "               'std_reward': 10.1615944197}),\n",
       "             (5679,\n",
       "              {'stats': {'sameRoom': 1139,\n",
       "                'agentInRoomID0': 1095,\n",
       "                'agentInRoomID1': 1153,\n",
       "                'targetInRoomID0': 1114,\n",
       "                'targetInRoomID1': 1134,\n",
       "                'episodeCount': 2248,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5679,\n",
       "                'targetRoomIndex0': 1114,\n",
       "                'targetRoomIndex1': 1134},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5679,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5679_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -37.55869166374207,\n",
       "               'std_reward': 12.8568521775}),\n",
       "             (4392,\n",
       "              {'stats': {'sameRoom': 2288,\n",
       "                'agentInRoomID0': 2280,\n",
       "                'agentInRoomID1': 2304,\n",
       "                'targetInRoomID0': 2308,\n",
       "                'targetInRoomID1': 2276,\n",
       "                'episodeCount': 4584,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4392,\n",
       "                'targetRoomIndex0': 2308,\n",
       "                'targetRoomIndex1': 2276},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4392,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4392_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -38.57536897659302,\n",
       "               'std_reward': 5.2236626475}),\n",
       "             (4121,\n",
       "              {'stats': {'sameRoom': 2302,\n",
       "                'agentInRoomID0': 2273,\n",
       "                'agentInRoomID1': 2328,\n",
       "                'targetInRoomID0': 2292,\n",
       "                'targetInRoomID1': 2309,\n",
       "                'episodeCount': 4601,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4121,\n",
       "                'targetRoomIndex0': 2292,\n",
       "                'targetRoomIndex1': 2309},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4121,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4121_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -39.18657293319702,\n",
       "               'std_reward': 5.1104992278}),\n",
       "             (4376,\n",
       "              {'stats': {'sameRoom': 2283,\n",
       "                'agentInRoomID0': 2298,\n",
       "                'agentInRoomID1': 2246,\n",
       "                'targetInRoomID0': 2259,\n",
       "                'targetInRoomID1': 2285,\n",
       "                'episodeCount': 4544,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4376,\n",
       "                'targetRoomIndex0': 2259,\n",
       "                'targetRoomIndex1': 2285},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 2000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 4376,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4376_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -40.55201641082763,\n",
       "               'std_reward': 5.5221423499}),\n",
       "             (5629,\n",
       "              {'stats': {'sameRoom': 1099,\n",
       "                'agentInRoomID0': 1122,\n",
       "                'agentInRoomID1': 1122,\n",
       "                'targetInRoomID0': 1117,\n",
       "                'targetInRoomID1': 1127,\n",
       "                'episodeCount': 2244,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5629,\n",
       "                'targetRoomIndex0': 1117,\n",
       "                'targetRoomIndex1': 1127},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5629,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5629_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '5e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -42.158379039764405,\n",
       "               'std_reward': 14.6630242148}),\n",
       "             (5204,\n",
       "              {'stats': {'sameRoom': 942,\n",
       "                'agentInRoomID0': 871,\n",
       "                'agentInRoomID1': 975,\n",
       "                'targetInRoomID0': 909,\n",
       "                'targetInRoomID1': 937,\n",
       "                'episodeCount': 1846,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5204,\n",
       "                'targetRoomIndex0': 909,\n",
       "                'targetRoomIndex1': 937},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5204,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5204_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -43.904233837127684,\n",
       "               'std_reward': 24.5817214115}),\n",
       "             (5426,\n",
       "              {'stats': {'sameRoom': 1123,\n",
       "                'agentInRoomID0': 1113,\n",
       "                'agentInRoomID1': 1125,\n",
       "                'targetInRoomID0': 1114,\n",
       "                'targetInRoomID1': 1124,\n",
       "                'episodeCount': 2238,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5426,\n",
       "                'targetRoomIndex0': 1114,\n",
       "                'targetRoomIndex1': 1124},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5426,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5426_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -44.342381896972654,\n",
       "               'std_reward': 16.3542368053}),\n",
       "             (5395,\n",
       "              {'stats': {'sameRoom': 1158,\n",
       "                'agentInRoomID0': 1124,\n",
       "                'agentInRoomID1': 1143,\n",
       "                'targetInRoomID0': 1145,\n",
       "                'targetInRoomID1': 1122,\n",
       "                'episodeCount': 2267,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5395,\n",
       "                'targetRoomIndex0': 1145,\n",
       "                'targetRoomIndex1': 1122},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5395,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5395_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -44.76278015136719,\n",
       "               'std_reward': 16.4143554602}),\n",
       "             (5635,\n",
       "              {'stats': {'sameRoom': 1116,\n",
       "                'agentInRoomID0': 1148,\n",
       "                'agentInRoomID1': 1137,\n",
       "                'targetInRoomID0': 1155,\n",
       "                'targetInRoomID1': 1130,\n",
       "                'episodeCount': 2285,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5635,\n",
       "                'targetRoomIndex0': 1155,\n",
       "                'targetRoomIndex1': 1130},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5635,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5635_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -45.812219257354734,\n",
       "               'std_reward': 17.0273070973}),\n",
       "             (5009,\n",
       "              {'stats': {'sameRoom': 1167,\n",
       "                'agentInRoomID0': 1177,\n",
       "                'agentInRoomID1': 1171,\n",
       "                'targetInRoomID0': 1168,\n",
       "                'targetInRoomID1': 1180,\n",
       "                'episodeCount': 2348,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5009,\n",
       "                'targetRoomIndex0': 1168,\n",
       "                'targetRoomIndex1': 1180},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5009,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5009_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -49.015307102203366,\n",
       "               'std_reward': 14.1406330044}),\n",
       "             (5809,\n",
       "              {'stats': {'sameRoom': 1165,\n",
       "                'agentInRoomID0': 1189,\n",
       "                'agentInRoomID1': 1192,\n",
       "                'targetInRoomID0': 1179,\n",
       "                'targetInRoomID1': 1202,\n",
       "                'episodeCount': 2381,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5809,\n",
       "                'targetRoomIndex0': 1179,\n",
       "                'targetRoomIndex1': 1202},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5809,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5809_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-4',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -51.65796552658081,\n",
       "               'std_reward': 11.9332942957}),\n",
       "             (4602,\n",
       "              {'stats': {'sameRoom': 1138,\n",
       "                'agentInRoomID0': 1155,\n",
       "                'agentInRoomID1': 1155,\n",
       "                'targetInRoomID0': 1127,\n",
       "                'targetInRoomID1': 1183,\n",
       "                'episodeCount': 2310,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4602,\n",
       "                'targetRoomIndex0': 1127,\n",
       "                'targetRoomIndex1': 1183},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 4602,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4602_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -55.55645597457886,\n",
       "               'std_reward': 13.448655282}),\n",
       "             (5227,\n",
       "              {'stats': {'sameRoom': 1183,\n",
       "                'agentInRoomID0': 1177,\n",
       "                'agentInRoomID1': 1225,\n",
       "                'targetInRoomID0': 1190,\n",
       "                'targetInRoomID1': 1212,\n",
       "                'episodeCount': 2402,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5227,\n",
       "                'targetRoomIndex0': 1190,\n",
       "                'targetRoomIndex1': 1212},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5227,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5227_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -62.476242790222166,\n",
       "               'std_reward': 12.9014093194}),\n",
       "             (5754,\n",
       "              {'stats': {'sameRoom': 1177,\n",
       "                'agentInRoomID0': 1186,\n",
       "                'agentInRoomID1': 1211,\n",
       "                'targetInRoomID0': 1194,\n",
       "                'targetInRoomID1': 1203,\n",
       "                'episodeCount': 2397,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5754,\n",
       "                'targetRoomIndex0': 1194,\n",
       "                'targetRoomIndex1': 1203},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5754,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5754_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -65.4411400604248,\n",
       "               'std_reward': 13.2133324689}),\n",
       "             (5370,\n",
       "              {'stats': {'sameRoom': 1201,\n",
       "                'agentInRoomID0': 1162,\n",
       "                'agentInRoomID1': 1181,\n",
       "                'targetInRoomID0': 1156,\n",
       "                'targetInRoomID1': 1187,\n",
       "                'episodeCount': 2343,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5370,\n",
       "                'targetRoomIndex0': 1156,\n",
       "                'targetRoomIndex1': 1187},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5370,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5370_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -66.18281295776367,\n",
       "               'std_reward': 13.8979145766}),\n",
       "             (4888,\n",
       "              {'stats': {'sameRoom': 1152,\n",
       "                'agentInRoomID0': 1144,\n",
       "                'agentInRoomID1': 1205,\n",
       "                'targetInRoomID0': 1169,\n",
       "                'targetInRoomID1': 1180,\n",
       "                'episodeCount': 2349,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4888,\n",
       "                'targetRoomIndex0': 1169,\n",
       "                'targetRoomIndex1': 1180},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 4888,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4888_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 248,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 102400,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -67.08430950164795,\n",
       "               'std_reward': 12.3371924409}),\n",
       "             (5208,\n",
       "              {'stats': {'sameRoom': 1179,\n",
       "                'agentInRoomID0': 1199,\n",
       "                'agentInRoomID1': 1193,\n",
       "                'targetInRoomID0': 1190,\n",
       "                'targetInRoomID1': 1202,\n",
       "                'episodeCount': 2392,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5208,\n",
       "                'targetRoomIndex0': 1190,\n",
       "                'targetRoomIndex1': 1202},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 5208,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5208_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -67.95171367645264,\n",
       "               'std_reward': 13.6177523445}),\n",
       "             (4776,\n",
       "              {'stats': {'sameRoom': 1117,\n",
       "                'agentInRoomID0': 1138,\n",
       "                'agentInRoomID1': 1165,\n",
       "                'targetInRoomID0': 1120,\n",
       "                'targetInRoomID1': 1183,\n",
       "                'episodeCount': 2303,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 4776,\n",
       "                'targetRoomIndex0': 1120,\n",
       "                'targetRoomIndex1': 1183},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 4776,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\4776_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -70.80645324707031,\n",
       "               'std_reward': 13.4525689182}),\n",
       "             (5866,\n",
       "              {'stats': {'sameRoom': 1239,\n",
       "                'agentInRoomID0': 1188,\n",
       "                'agentInRoomID1': 1198,\n",
       "                'targetInRoomID0': 1167,\n",
       "                'targetInRoomID1': 1219,\n",
       "                'episodeCount': 2386,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5866,\n",
       "                'targetRoomIndex0': 1167,\n",
       "                'targetRoomIndex1': 1219},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5866,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5866_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-3',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'constant',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 1500,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -74.85526386260986,\n",
       "               'std_reward': 16.8709473743}),\n",
       "             (5385,\n",
       "              {'stats': {'sameRoom': 1146,\n",
       "                'agentInRoomID0': 1148,\n",
       "                'agentInRoomID1': 1174,\n",
       "                'targetInRoomID0': 1138,\n",
       "                'targetInRoomID1': 1184,\n",
       "                'episodeCount': 2322,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5385,\n",
       "                'targetRoomIndex0': 1138,\n",
       "                'targetRoomIndex1': 1184},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5385,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5385_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 64,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -77.52755886077881,\n",
       "               'std_reward': 15.0214065702}),\n",
       "             (5529,\n",
       "              {'stats': {'sameRoom': 1135,\n",
       "                'agentInRoomID0': 1165,\n",
       "                'agentInRoomID1': 1136,\n",
       "                'targetInRoomID0': 1135,\n",
       "                'targetInRoomID1': 1166,\n",
       "                'episodeCount': 2301,\n",
       "                'sensorCount': 1,\n",
       "                'runId': 5529,\n",
       "                'targetRoomIndex0': 1135,\n",
       "                'targetRoomIndex1': 1166},\n",
       "               'unity_config': {'sensorCount': 1,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 5000,\n",
       "                'stepPenalty': -0.0025,\n",
       "                'runId': 5529,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\5529_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 204800,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-5',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '1.5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 64},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 512,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'mean_reward': -78.74414741516114,\n",
       "               'std_reward': 15.3353890688})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict = OrderedDict(\n",
    "            sorted(\n",
    "                selected_ids_dict.items(), key=lambda v: v[1][\"mean_reward\"], reverse=True\n",
    "            )\n",
    "        )\n",
    "sorted_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
