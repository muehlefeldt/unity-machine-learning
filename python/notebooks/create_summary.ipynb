{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summary of the requested runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_run = 6179\n",
    "to_run = 6406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_dict(paths_dict: dict) -> dict:\n",
    "    result = {}\n",
    "    #dir_contents: list = []\n",
    "    for key in paths_dict:\n",
    "        if key != \"working_dir\":\n",
    "            dir_contents = os.listdir(paths_dict[key])\n",
    "    \n",
    "            #numbers = []\n",
    "            #rest_of_file_name: str = \"\"\n",
    "            for entry in dir_contents:\n",
    "                number = 0\n",
    "                if \"_\" in entry:\n",
    "                    number = int(entry.split(\"_\")[0])\n",
    "                    #rest_of_file_name = str.join(\"_\", entry.split(\"_\")[1:])\n",
    "                    \n",
    "                else:\n",
    "                    number = int(entry.split(\".\")[0])\n",
    "                    #rest_of_file_name = str.join(\".\", entry.split(\".\")[1:])\n",
    "                    \n",
    "                if number not in result:\n",
    "                    result[number] = {}\n",
    "                    \n",
    "                result[number][key] = paths_dict[key] / f\"{entry}\"\n",
    "    #if not numbers:\n",
    "    #    return []\n",
    "    \n",
    "            #for num in numbers:\n",
    "                \n",
    "    \n",
    "    # Remove double entries and sort.\n",
    "    #result = dict.fromkeys(numbers)\n",
    "    #result.sort()\n",
    "\n",
    "    #for key in result:\n",
    "    #    result[key] = {}\n",
    "    #    result[key][\"summary_path\"] = paths_dict[\"summaries_dir\"] / f\"{key}_summary.json\"\n",
    "    #    result[key][\"result_path\"] = paths_dict[\"summaries_dir\"] / f\"{key}_summary.json\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_overview(path: Path, unity: dict) -> dict:\n",
    "    \"\"\"Get the mean reward over the last 5 cumulative rewards entries in the tfevents file.\"\"\"\n",
    "    cumulative_rewards = []\n",
    "    ep_length = []\n",
    "\n",
    "    # Get the tfevents file associated with the current run.\n",
    "    path_to_result_folder = path / \"RollerAgent/\"\n",
    "    try:\n",
    "        path_to_result = sorted(Path(path_to_result_folder).glob(\"events.out.tfevents.*\"))[0]\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    # Using tensorflow to access the tfevents data.\n",
    "    # datarecord = EventFileLoader(str(path_to_result)).Load()\n",
    "    for event in EventFileLoader(str(path_to_result)).Load():\n",
    "        # event = event_pb2.Event.FromString(batch.numpy())\n",
    "        for value in event.summary.value:\n",
    "            if value.tag == \"Environment/Cumulative Reward\":\n",
    "                cumulative_rewards.append(value.tensor.float_val[0])\n",
    "            if value.tag == \"Environment/Episode Length\":\n",
    "                ep_length.append(value.tensor.float_val[0])\n",
    "\n",
    "    # Return mean of the last 5 recorded cummulative rewards.\n",
    "    rewards_of_interest = cumulative_rewards[-100:]\n",
    "    return {\"mean_reward\": np.mean(rewards_of_interest), \n",
    "            \"std_mean_reward\": np.round(np.std(rewards_of_interest), 5),\n",
    "            \"episode_length\": np.mean(ep_length[-100:]),\n",
    "            \"normalised_reward\": np.mean(rewards_of_interest) / unity[\"maxStep\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'working_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env'),\n",
       " 'results_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/results'),\n",
       " 'results_archive_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/results_archive'),\n",
       " 'stats_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/stats'),\n",
       " 'summaries_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/summaries'),\n",
       " 'configs_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/configs'),\n",
       " 'unity_configs_dir': WindowsPath('C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env/unity_configs')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter paths for plot creation and get absolute paths.\n",
    "paths = {\n",
    "        \"working_dir\": \"C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/python/basic_rl_env\",\n",
    "        \"results_dir\": \"results/\",\n",
    "        \"results_archive_dir\": \"results_archive/\",\n",
    "        \"stats_dir\": \"stats/\",\n",
    "        \"summaries_dir\": \"summaries/\",\n",
    "        \"configs_dir\": \"configs/\",\n",
    "        \"unity_configs_dir\": \"unity_configs/\"\n",
    "    }\n",
    "\n",
    "paths[\"working_dir\"] = Path(paths[\"working_dir\"]).absolute()\n",
    "\n",
    "for key in paths:\n",
    "    if key != \"working_dir\":\n",
    "        paths[key] = paths[\"working_dir\"] / paths[key]\n",
    "        \n",
    "\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6181,\n",
       " 6190,\n",
       " 6191,\n",
       " 6195,\n",
       " 6202,\n",
       " 6230,\n",
       " 6235,\n",
       " 6239,\n",
       " 6241,\n",
       " 6245,\n",
       " 6247,\n",
       " 6249,\n",
       " 6251,\n",
       " 6268,\n",
       " 6271,\n",
       " 6276,\n",
       " 6278,\n",
       " 6286,\n",
       " 6291,\n",
       " 6293,\n",
       " 6297,\n",
       " 6299,\n",
       " 6303,\n",
       " 6306,\n",
       " 6309,\n",
       " 6323,\n",
       " 6326,\n",
       " 6328,\n",
       " 6330,\n",
       " 6339,\n",
       " 6344,\n",
       " 6345,\n",
       " 6351,\n",
       " 6353,\n",
       " 6363,\n",
       " 6367,\n",
       " 6371,\n",
       " 6373,\n",
       " 6375,\n",
       " 6378,\n",
       " 6387,\n",
       " 6397,\n",
       " 6398,\n",
       " 6400,\n",
       " 6402,\n",
       " 6405,\n",
       " 6406,\n",
       " 6183,\n",
       " 6203]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dict = get_run_dict(paths)\n",
    "\n",
    "selected_ids = [x for x in run_dict.keys() if from_run <= x <= to_run]\n",
    "selected_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6181: {'stats': {'sameRoom': 14411,\n",
       "   'agentInRoomID0': 14237,\n",
       "   'agentInRoomID1': 14532,\n",
       "   'targetInRoomID0': 14457,\n",
       "   'targetInRoomID1': 14312,\n",
       "   'episodeCount': 28769,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6181,\n",
       "   'targetRoomIndex0': 14457,\n",
       "   'targetRoomIndex1': 14312},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6181,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6181_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2304030789155513,\n",
       "   'std_mean_reward': 0.12548,\n",
       "   'episode_length': 166.03373168945313,\n",
       "   'normalised_reward': -0.00023040307891555132}},\n",
       " 6190: {'stats': {'sameRoom': 14203,\n",
       "   'agentInRoomID0': 14281,\n",
       "   'agentInRoomID1': 14045,\n",
       "   'targetInRoomID0': 14202,\n",
       "   'targetInRoomID1': 14124,\n",
       "   'episodeCount': 28326,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6190,\n",
       "   'targetRoomIndex0': 14202,\n",
       "   'targetRoomIndex1': 14124},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6190,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6190_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.25859064191579817,\n",
       "   'std_mean_reward': 0.11902,\n",
       "   'episode_length': 167.7788700866699,\n",
       "   'normalised_reward': -0.0002585906419157982}},\n",
       " 6191: {'stats': {'sameRoom': 14524,\n",
       "   'agentInRoomID0': 14476,\n",
       "   'agentInRoomID1': 14501,\n",
       "   'targetInRoomID0': 14527,\n",
       "   'targetInRoomID1': 14450,\n",
       "   'episodeCount': 28977,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6191,\n",
       "   'targetRoomIndex0': 14527,\n",
       "   'targetRoomIndex1': 14450},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6191,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6191_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.20882328735664488,\n",
       "   'std_mean_reward': 0.13161,\n",
       "   'episode_length': 162.9525895690918,\n",
       "   'normalised_reward': -0.00020882328735664487}},\n",
       " 6195: {'stats': {'sameRoom': 14633,\n",
       "   'agentInRoomID0': 14545,\n",
       "   'agentInRoomID1': 14408,\n",
       "   'targetInRoomID0': 14465,\n",
       "   'targetInRoomID1': 14488,\n",
       "   'episodeCount': 28953,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6195,\n",
       "   'targetRoomIndex0': 14465,\n",
       "   'targetRoomIndex1': 14488},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6195,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6195_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2371140659181401,\n",
       "   'std_mean_reward': 0.13689,\n",
       "   'episode_length': 163.54295333862305,\n",
       "   'normalised_reward': -0.0002371140659181401}},\n",
       " 6202: {'stats': {'sameRoom': 14916,\n",
       "   'agentInRoomID0': 14919,\n",
       "   'agentInRoomID1': 14909,\n",
       "   'targetInRoomID0': 14927,\n",
       "   'targetInRoomID1': 14901,\n",
       "   'episodeCount': 29828,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6202,\n",
       "   'targetRoomIndex0': 14927,\n",
       "   'targetRoomIndex1': 14901},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6202,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6202_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.13076711568748578,\n",
       "   'std_mean_reward': 0.14214,\n",
       "   'episode_length': 154.391163482666,\n",
       "   'normalised_reward': -0.00013076711568748577}},\n",
       " 6230: {'stats': {'sameRoom': 14641,\n",
       "   'agentInRoomID0': 14449,\n",
       "   'agentInRoomID1': 14435,\n",
       "   'targetInRoomID0': 14418,\n",
       "   'targetInRoomID1': 14466,\n",
       "   'episodeCount': 28884,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6230,\n",
       "   'targetRoomIndex0': 14418,\n",
       "   'targetRoomIndex1': 14466},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6230,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6230_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.22329374431166799,\n",
       "   'std_mean_reward': 0.1162,\n",
       "   'episode_length': 164.266328125,\n",
       "   'normalised_reward': -0.000223293744311668}},\n",
       " 6235: {'stats': {'sameRoom': 14232,\n",
       "   'agentInRoomID0': 14220,\n",
       "   'agentInRoomID1': 14198,\n",
       "   'targetInRoomID0': 14108,\n",
       "   'targetInRoomID1': 14310,\n",
       "   'episodeCount': 28418,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6235,\n",
       "   'targetRoomIndex0': 14108,\n",
       "   'targetRoomIndex1': 14310},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6235,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6235_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.20758897423744202,\n",
       "   'std_mean_reward': 0.10909,\n",
       "   'episode_length': 165.29003479003907,\n",
       "   'normalised_reward': -0.00020758897423744203}},\n",
       " 6239: {'stats': {'sameRoom': 14614,\n",
       "   'agentInRoomID0': 14307,\n",
       "   'agentInRoomID1': 14529,\n",
       "   'targetInRoomID0': 14467,\n",
       "   'targetInRoomID1': 14369,\n",
       "   'episodeCount': 28836,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6239,\n",
       "   'targetRoomIndex0': 14467,\n",
       "   'targetRoomIndex1': 14369},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6239,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6239_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3106884836498648,\n",
       "   'std_mean_reward': 0.15953,\n",
       "   'episode_length': 168.05660461425782,\n",
       "   'normalised_reward': -0.0003106884836498648}},\n",
       " 6241: {'stats': {'sameRoom': 14215,\n",
       "   'agentInRoomID0': 14196,\n",
       "   'agentInRoomID1': 14214,\n",
       "   'targetInRoomID0': 14183,\n",
       "   'targetInRoomID1': 14227,\n",
       "   'episodeCount': 28410,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6241,\n",
       "   'targetRoomIndex0': 14183,\n",
       "   'targetRoomIndex1': 14227},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6241,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6241_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2361103981602355,\n",
       "   'std_mean_reward': 0.15887,\n",
       "   'episode_length': 163.8843295288086,\n",
       "   'normalised_reward': -0.00023611039816023548}},\n",
       " 6245: {'stats': {'sameRoom': 14257,\n",
       "   'agentInRoomID0': 14114,\n",
       "   'agentInRoomID1': 14471,\n",
       "   'targetInRoomID0': 14204,\n",
       "   'targetInRoomID1': 14381,\n",
       "   'episodeCount': 28585,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6245,\n",
       "   'targetRoomIndex0': 14204,\n",
       "   'targetRoomIndex1': 14381},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6245,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6245_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2668987016007304,\n",
       "   'std_mean_reward': 0.12063,\n",
       "   'episode_length': 165.6969137573242,\n",
       "   'normalised_reward': -0.0002668987016007304}},\n",
       " 6247: {'stats': {'sameRoom': 13813,\n",
       "   'agentInRoomID0': 13932,\n",
       "   'agentInRoomID1': 14020,\n",
       "   'targetInRoomID0': 14077,\n",
       "   'targetInRoomID1': 13875,\n",
       "   'episodeCount': 27952,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6247,\n",
       "   'targetRoomIndex0': 14077,\n",
       "   'targetRoomIndex1': 13875},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6247,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6247_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3009951530396938,\n",
       "   'std_mean_reward': 0.11029,\n",
       "   'episode_length': 174.37648803710937,\n",
       "   'normalised_reward': -0.0003009951530396938}},\n",
       " 6249: {'stats': {'sameRoom': 14038,\n",
       "   'agentInRoomID0': 13883,\n",
       "   'agentInRoomID1': 14208,\n",
       "   'targetInRoomID0': 14052,\n",
       "   'targetInRoomID1': 14039,\n",
       "   'episodeCount': 28091,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6249,\n",
       "   'targetRoomIndex0': 14052,\n",
       "   'targetRoomIndex1': 14039},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6249,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6249_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3292365188896656,\n",
       "   'std_mean_reward': 0.12103,\n",
       "   'episode_length': 172.63443984985352,\n",
       "   'normalised_reward': -0.0003292365188896656}},\n",
       " 6251: {'stats': {'sameRoom': 14135,\n",
       "   'agentInRoomID0': 14026,\n",
       "   'agentInRoomID1': 14319,\n",
       "   'targetInRoomID0': 14144,\n",
       "   'targetInRoomID1': 14201,\n",
       "   'episodeCount': 28345,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6251,\n",
       "   'targetRoomIndex0': 14144,\n",
       "   'targetRoomIndex1': 14201},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6251,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6251_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2686461552232504,\n",
       "   'std_mean_reward': 0.12148,\n",
       "   'episode_length': 168.59771713256836,\n",
       "   'normalised_reward': -0.0002686461552232504}},\n",
       " 6268: {'stats': {'sameRoom': 14345,\n",
       "   'agentInRoomID0': 14395,\n",
       "   'agentInRoomID1': 14231,\n",
       "   'targetInRoomID0': 14286,\n",
       "   'targetInRoomID1': 14340,\n",
       "   'episodeCount': 28626,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6268,\n",
       "   'targetRoomIndex0': 14286,\n",
       "   'targetRoomIndex1': 14340},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6268,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6268_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.20502461072057485,\n",
       "   'std_mean_reward': 0.10139,\n",
       "   'episode_length': 163.77803817749023,\n",
       "   'normalised_reward': -0.00020502461072057485}},\n",
       " 6271: {'stats': {'sameRoom': 14115,\n",
       "   'agentInRoomID0': 14047,\n",
       "   'agentInRoomID1': 14041,\n",
       "   'targetInRoomID0': 13986,\n",
       "   'targetInRoomID1': 14102,\n",
       "   'episodeCount': 28088,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6271,\n",
       "   'targetRoomIndex0': 13986,\n",
       "   'targetRoomIndex1': 14102},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6271,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6271_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.28226251363754273,\n",
       "   'std_mean_reward': 0.11132,\n",
       "   'episode_length': 168.906513671875,\n",
       "   'normalised_reward': -0.00028226251363754274}},\n",
       " 6276: {'stats': {'sameRoom': 14279,\n",
       "   'agentInRoomID0': 14311,\n",
       "   'agentInRoomID1': 14261,\n",
       "   'targetInRoomID0': 14256,\n",
       "   'targetInRoomID1': 14316,\n",
       "   'episodeCount': 28572,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6276,\n",
       "   'targetRoomIndex0': 14256,\n",
       "   'targetRoomIndex1': 14316},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6276,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6276_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.20926464358344674,\n",
       "   'std_mean_reward': 0.10375,\n",
       "   'episode_length': 165.83152282714843,\n",
       "   'normalised_reward': -0.00020926464358344673}},\n",
       " 6278: {'stats': {'sameRoom': 5139,\n",
       "   'agentInRoomID0': 5157,\n",
       "   'agentInRoomID1': 5059,\n",
       "   'targetInRoomID0': 5106,\n",
       "   'targetInRoomID1': 5110,\n",
       "   'episodeCount': 10216,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6278,\n",
       "   'targetRoomIndex0': 5106,\n",
       "   'targetRoomIndex1': 5110},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6278,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6278_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.6078064243495465,\n",
       "   'std_mean_reward': 0.26618,\n",
       "   'episode_length': 179.78206909179687,\n",
       "   'normalised_reward': -0.0006078064243495465}},\n",
       " 6286: {'stats': {'sameRoom': 14035,\n",
       "   'agentInRoomID0': 14083,\n",
       "   'agentInRoomID1': 14023,\n",
       "   'targetInRoomID0': 14054,\n",
       "   'targetInRoomID1': 14052,\n",
       "   'episodeCount': 28106,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6286,\n",
       "   'targetRoomIndex0': 14054,\n",
       "   'targetRoomIndex1': 14052},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6286,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6286_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.30389424227178097,\n",
       "   'std_mean_reward': 0.1109,\n",
       "   'episode_length': 173.1688494873047,\n",
       "   'normalised_reward': -0.00030389424227178095}},\n",
       " 6291: {'stats': {'sameRoom': 14359,\n",
       "   'agentInRoomID0': 14250,\n",
       "   'agentInRoomID1': 14456,\n",
       "   'targetInRoomID0': 14411,\n",
       "   'targetInRoomID1': 14295,\n",
       "   'episodeCount': 28706,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6291,\n",
       "   'targetRoomIndex0': 14411,\n",
       "   'targetRoomIndex1': 14295},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6291,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6291_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2343151248033246,\n",
       "   'std_mean_reward': 0.12082,\n",
       "   'episode_length': 163.10093948364258,\n",
       "   'normalised_reward': -0.0002343151248033246}},\n",
       " 6293: {'stats': {'sameRoom': 14492,\n",
       "   'agentInRoomID0': 14449,\n",
       "   'agentInRoomID1': 14399,\n",
       "   'targetInRoomID0': 14353,\n",
       "   'targetInRoomID1': 14495,\n",
       "   'episodeCount': 28848,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6293,\n",
       "   'targetRoomIndex0': 14353,\n",
       "   'targetRoomIndex1': 14495},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6293,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6293_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.17947203435003758,\n",
       "   'std_mean_reward': 0.1504,\n",
       "   'episode_length': 158.98133239746093,\n",
       "   'normalised_reward': -0.0001794720343500376}},\n",
       " 6297: {'stats': {'sameRoom': 14241,\n",
       "   'agentInRoomID0': 14166,\n",
       "   'agentInRoomID1': 14230,\n",
       "   'targetInRoomID0': 14187,\n",
       "   'targetInRoomID1': 14209,\n",
       "   'episodeCount': 28396,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6297,\n",
       "   'targetRoomIndex0': 14187,\n",
       "   'targetRoomIndex1': 14209},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6297,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6297_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.248363663807977,\n",
       "   'std_mean_reward': 0.1542,\n",
       "   'episode_length': 167.23421813964845,\n",
       "   'normalised_reward': -0.000248363663807977}},\n",
       " 6299: {'stats': {'sameRoom': 14302,\n",
       "   'agentInRoomID0': 14205,\n",
       "   'agentInRoomID1': 14373,\n",
       "   'targetInRoomID0': 14279,\n",
       "   'targetInRoomID1': 14299,\n",
       "   'episodeCount': 28578,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6299,\n",
       "   'targetRoomIndex0': 14279,\n",
       "   'targetRoomIndex1': 14299},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6299,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6299_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2832967826165259,\n",
       "   'std_mean_reward': 0.14676,\n",
       "   'episode_length': 163.51846649169923,\n",
       "   'normalised_reward': -0.0002832967826165259}},\n",
       " 6303: {'stats': {'sameRoom': 14049,\n",
       "   'agentInRoomID0': 14190,\n",
       "   'agentInRoomID1': 13910,\n",
       "   'targetInRoomID0': 13953,\n",
       "   'targetInRoomID1': 14147,\n",
       "   'episodeCount': 28100,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6303,\n",
       "   'targetRoomIndex0': 13953,\n",
       "   'targetRoomIndex1': 14147},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6303,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6303_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.26092289347201586,\n",
       "   'std_mean_reward': 0.1062,\n",
       "   'episode_length': 168.48914947509766,\n",
       "   'normalised_reward': -0.00026092289347201585}},\n",
       " 6306: {'stats': {'sameRoom': 14329,\n",
       "   'agentInRoomID0': 14358,\n",
       "   'agentInRoomID1': 14265,\n",
       "   'targetInRoomID0': 14316,\n",
       "   'targetInRoomID1': 14307,\n",
       "   'episodeCount': 28623,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6306,\n",
       "   'targetRoomIndex0': 14316,\n",
       "   'targetRoomIndex1': 14307},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6306,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6306_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2454745088145137,\n",
       "   'std_mean_reward': 0.11366,\n",
       "   'episode_length': 166.9709635925293,\n",
       "   'normalised_reward': -0.00024547450881451366}},\n",
       " 6309: {'stats': {'sameRoom': 13891,\n",
       "   'agentInRoomID0': 14058,\n",
       "   'agentInRoomID1': 13824,\n",
       "   'targetInRoomID0': 13959,\n",
       "   'targetInRoomID1': 13923,\n",
       "   'episodeCount': 27882,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6309,\n",
       "   'targetRoomIndex0': 13959,\n",
       "   'targetRoomIndex1': 13923},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6309,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6309_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.29826728712767364,\n",
       "   'std_mean_reward': 0.14118,\n",
       "   'episode_length': 170.6179753112793,\n",
       "   'normalised_reward': -0.00029826728712767364}},\n",
       " 6323: {'stats': {'sameRoom': 14313,\n",
       "   'agentInRoomID0': 14252,\n",
       "   'agentInRoomID1': 14233,\n",
       "   'targetInRoomID0': 14340,\n",
       "   'targetInRoomID1': 14145,\n",
       "   'episodeCount': 28485,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6323,\n",
       "   'targetRoomIndex0': 14340,\n",
       "   'targetRoomIndex1': 14145},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6323,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6323_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2602912992425263,\n",
       "   'std_mean_reward': 0.10913,\n",
       "   'episode_length': 167.82647537231446,\n",
       "   'normalised_reward': -0.0002602912992425263}},\n",
       " 6326: {'stats': {'sameRoom': 69,\n",
       "   'agentInRoomID0': 72,\n",
       "   'agentInRoomID1': 60,\n",
       "   'targetInRoomID0': 67,\n",
       "   'targetInRoomID1': 65,\n",
       "   'episodeCount': 132,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6326,\n",
       "   'targetRoomIndex0': 67,\n",
       "   'targetRoomIndex1': 65},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6326,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6326_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': nan,\n",
       "   'std_mean_reward': nan,\n",
       "   'episode_length': nan,\n",
       "   'normalised_reward': nan}},\n",
       " 6328: {'stats': {'sameRoom': 14036,\n",
       "   'agentInRoomID0': 13918,\n",
       "   'agentInRoomID1': 14206,\n",
       "   'targetInRoomID0': 14028,\n",
       "   'targetInRoomID1': 14096,\n",
       "   'episodeCount': 28124,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6328,\n",
       "   'targetRoomIndex0': 14028,\n",
       "   'targetRoomIndex1': 14096},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6328,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6328_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.24723626595921813,\n",
       "   'std_mean_reward': 0.11161,\n",
       "   'episode_length': 167.85951873779297,\n",
       "   'normalised_reward': -0.00024723626595921815}},\n",
       " 6330: {'stats': {'sameRoom': 13994,\n",
       "   'agentInRoomID0': 13986,\n",
       "   'agentInRoomID1': 13966,\n",
       "   'targetInRoomID0': 13834,\n",
       "   'targetInRoomID1': 14118,\n",
       "   'episodeCount': 27952,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6330,\n",
       "   'targetRoomIndex0': 13834,\n",
       "   'targetRoomIndex1': 14118},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6330,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6330_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.32580278903245924,\n",
       "   'std_mean_reward': 0.13219,\n",
       "   'episode_length': 171.3531185913086,\n",
       "   'normalised_reward': -0.00032580278903245925}},\n",
       " 6339: {'stats': {'sameRoom': 14131,\n",
       "   'agentInRoomID0': 13986,\n",
       "   'agentInRoomID1': 14025,\n",
       "   'targetInRoomID0': 14042,\n",
       "   'targetInRoomID1': 13969,\n",
       "   'episodeCount': 28011,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6339,\n",
       "   'targetRoomIndex0': 14042,\n",
       "   'targetRoomIndex1': 13969},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6339,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6339_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.323274797424674,\n",
       "   'std_mean_reward': 0.12291,\n",
       "   'episode_length': 170.8819445800781,\n",
       "   'normalised_reward': -0.000323274797424674}},\n",
       " 6344: {'stats': {'sameRoom': 14080,\n",
       "   'agentInRoomID0': 14021,\n",
       "   'agentInRoomID1': 13994,\n",
       "   'targetInRoomID0': 13958,\n",
       "   'targetInRoomID1': 14057,\n",
       "   'episodeCount': 28015,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6344,\n",
       "   'targetRoomIndex0': 13958,\n",
       "   'targetRoomIndex1': 14057},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6344,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6344_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 2},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.31808342412114143,\n",
       "   'std_mean_reward': 0.14048,\n",
       "   'episode_length': 171.48535690307617,\n",
       "   'normalised_reward': -0.00031808342412114146}},\n",
       " 6345: {'stats': {'sameRoom': 13825,\n",
       "   'agentInRoomID0': 13827,\n",
       "   'agentInRoomID1': 13827,\n",
       "   'targetInRoomID0': 13894,\n",
       "   'targetInRoomID1': 13760,\n",
       "   'episodeCount': 27654,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6345,\n",
       "   'targetRoomIndex0': 13894,\n",
       "   'targetRoomIndex1': 13760},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6345,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6345_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.34842287011444567,\n",
       "   'std_mean_reward': 0.1582,\n",
       "   'episode_length': 173.005223236084,\n",
       "   'normalised_reward': -0.0003484228701144457}},\n",
       " 6351: {'stats': {'sameRoom': 14219,\n",
       "   'agentInRoomID0': 14103,\n",
       "   'agentInRoomID1': 14334,\n",
       "   'targetInRoomID0': 14207,\n",
       "   'targetInRoomID1': 14230,\n",
       "   'episodeCount': 28437,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6351,\n",
       "   'targetRoomIndex0': 14207,\n",
       "   'targetRoomIndex1': 14230},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6351,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6351_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.23950779225677252,\n",
       "   'std_mean_reward': 0.12799,\n",
       "   'episode_length': 167.17878845214844,\n",
       "   'normalised_reward': -0.00023950779225677252}},\n",
       " 6353: {'stats': {'sameRoom': 13794,\n",
       "   'agentInRoomID0': 13790,\n",
       "   'agentInRoomID1': 13877,\n",
       "   'targetInRoomID0': 13811,\n",
       "   'targetInRoomID1': 13856,\n",
       "   'episodeCount': 27667,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6353,\n",
       "   'targetRoomIndex0': 13811,\n",
       "   'targetRoomIndex1': 13856},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6353,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6353_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2648521926254034,\n",
       "   'std_mean_reward': 0.11491,\n",
       "   'episode_length': 170.51665618896484,\n",
       "   'normalised_reward': -0.00026485219262540336}},\n",
       " 6363: {'stats': {'sameRoom': 13926,\n",
       "   'agentInRoomID0': 13771,\n",
       "   'agentInRoomID1': 13766,\n",
       "   'targetInRoomID0': 13728,\n",
       "   'targetInRoomID1': 13809,\n",
       "   'episodeCount': 27537,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6363,\n",
       "   'targetRoomIndex0': 13728,\n",
       "   'targetRoomIndex1': 13809},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6363,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6363_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.36264205232262614,\n",
       "   'std_mean_reward': 0.12673,\n",
       "   'episode_length': 175.55774139404298,\n",
       "   'normalised_reward': -0.00036264205232262615}},\n",
       " 6367: {'stats': {'sameRoom': 13692,\n",
       "   'agentInRoomID0': 13713,\n",
       "   'agentInRoomID1': 13700,\n",
       "   'targetInRoomID0': 13564,\n",
       "   'targetInRoomID1': 13849,\n",
       "   'episodeCount': 27413,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6367,\n",
       "   'targetRoomIndex0': 13564,\n",
       "   'targetRoomIndex1': 13849},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6367,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6367_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.32023403123021127,\n",
       "   'std_mean_reward': 0.11171,\n",
       "   'episode_length': 173.24710708618164,\n",
       "   'normalised_reward': -0.00032023403123021126}},\n",
       " 6371: {'stats': {'sameRoom': 13820,\n",
       "   'agentInRoomID0': 13775,\n",
       "   'agentInRoomID1': 13628,\n",
       "   'targetInRoomID0': 13726,\n",
       "   'targetInRoomID1': 13677,\n",
       "   'episodeCount': 27403,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6371,\n",
       "   'targetRoomIndex0': 13726,\n",
       "   'targetRoomIndex1': 13677},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6371,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6371_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.30259506825357674,\n",
       "   'std_mean_reward': 0.11411,\n",
       "   'episode_length': 174.54285263061524,\n",
       "   'normalised_reward': -0.00030259506825357674}},\n",
       " 6373: {'stats': {'sameRoom': 13960,\n",
       "   'agentInRoomID0': 13834,\n",
       "   'agentInRoomID1': 14115,\n",
       "   'targetInRoomID0': 13965,\n",
       "   'targetInRoomID1': 13984,\n",
       "   'episodeCount': 27949,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6373,\n",
       "   'targetRoomIndex0': 13965,\n",
       "   'targetRoomIndex1': 13984},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6373,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6373_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.25447233198210595,\n",
       "   'std_mean_reward': 0.1113,\n",
       "   'episode_length': 166.79032577514647,\n",
       "   'normalised_reward': -0.0002544723319821059}},\n",
       " 6375: {'stats': {'sameRoom': 13647,\n",
       "   'agentInRoomID0': 13672,\n",
       "   'agentInRoomID1': 13478,\n",
       "   'targetInRoomID0': 13637,\n",
       "   'targetInRoomID1': 13513,\n",
       "   'episodeCount': 27150,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6375,\n",
       "   'targetRoomIndex0': 13637,\n",
       "   'targetRoomIndex1': 13513},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6375,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6375_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3574017135798931,\n",
       "   'std_mean_reward': 0.10498,\n",
       "   'episode_length': 178.83748657226562,\n",
       "   'normalised_reward': -0.00035740171357989307}},\n",
       " 6378: {'stats': {'sameRoom': 13712,\n",
       "   'agentInRoomID0': 13746,\n",
       "   'agentInRoomID1': 13871,\n",
       "   'targetInRoomID0': 13571,\n",
       "   'targetInRoomID1': 14046,\n",
       "   'episodeCount': 27617,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6378,\n",
       "   'targetRoomIndex0': 13571,\n",
       "   'targetRoomIndex1': 14046},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6378,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6378_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.27425402622669937,\n",
       "   'std_mean_reward': 0.11976,\n",
       "   'episode_length': 169.69782363891602,\n",
       "   'normalised_reward': -0.00027425402622669934}},\n",
       " 6387: {'stats': {'sameRoom': 13512,\n",
       "   'agentInRoomID0': 13685,\n",
       "   'agentInRoomID1': 13658,\n",
       "   'targetInRoomID0': 13600,\n",
       "   'targetInRoomID1': 13743,\n",
       "   'episodeCount': 27343,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6387,\n",
       "   'targetRoomIndex0': 13600,\n",
       "   'targetRoomIndex1': 13743},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6387,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6387_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3602246770262718,\n",
       "   'std_mean_reward': 0.16931,\n",
       "   'episode_length': 175.1582518005371,\n",
       "   'normalised_reward': -0.0003602246770262718}},\n",
       " 6397: {'stats': {'sameRoom': 13614,\n",
       "   'agentInRoomID0': 13698,\n",
       "   'agentInRoomID1': 13662,\n",
       "   'targetInRoomID0': 13856,\n",
       "   'targetInRoomID1': 13504,\n",
       "   'episodeCount': 27360,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6397,\n",
       "   'targetRoomIndex0': 13856,\n",
       "   'targetRoomIndex1': 13504},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6397,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6397_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.30523468628525735,\n",
       "   'std_mean_reward': 0.12182,\n",
       "   'episode_length': 173.30019439697264,\n",
       "   'normalised_reward': -0.00030523468628525734}},\n",
       " 6398: {'stats': {'sameRoom': 13865,\n",
       "   'agentInRoomID0': 13782,\n",
       "   'agentInRoomID1': 13870,\n",
       "   'targetInRoomID0': 13781,\n",
       "   'targetInRoomID1': 13871,\n",
       "   'episodeCount': 27652,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6398,\n",
       "   'targetRoomIndex0': 13781,\n",
       "   'targetRoomIndex1': 13871},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6398,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6398_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.2761340121179819,\n",
       "   'std_mean_reward': 0.11775,\n",
       "   'episode_length': 170.3212809753418,\n",
       "   'normalised_reward': -0.0002761340121179819}},\n",
       " 6400: {'stats': {'sameRoom': 14179,\n",
       "   'agentInRoomID0': 14008,\n",
       "   'agentInRoomID1': 14320,\n",
       "   'targetInRoomID0': 14149,\n",
       "   'targetInRoomID1': 14179,\n",
       "   'episodeCount': 28328,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6400,\n",
       "   'targetRoomIndex0': 14149,\n",
       "   'targetRoomIndex1': 14179},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6400,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6400_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.292469427511096,\n",
       "   'std_mean_reward': 0.13854,\n",
       "   'episode_length': 167.16640258789062,\n",
       "   'normalised_reward': -0.000292469427511096}},\n",
       " 6402: {'stats': {'sameRoom': 13637,\n",
       "   'agentInRoomID0': 13714,\n",
       "   'agentInRoomID1': 13775,\n",
       "   'targetInRoomID0': 13618,\n",
       "   'targetInRoomID1': 13871,\n",
       "   'episodeCount': 27489,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6402,\n",
       "   'targetRoomIndex0': 13618,\n",
       "   'targetRoomIndex1': 13871},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6402,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6402_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 16},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3485051322728395,\n",
       "   'std_mean_reward': 0.12221,\n",
       "   'episode_length': 174.90239685058594,\n",
       "   'normalised_reward': -0.00034850513227283953}},\n",
       " 6405: {'stats': {'sameRoom': 13158,\n",
       "   'agentInRoomID0': 13411,\n",
       "   'agentInRoomID1': 13221,\n",
       "   'targetInRoomID0': 13371,\n",
       "   'targetInRoomID1': 13261,\n",
       "   'episodeCount': 26632,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6405,\n",
       "   'targetRoomIndex0': 13371,\n",
       "   'targetRoomIndex1': 13261},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6405,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6405_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.44198483794927595,\n",
       "   'std_mean_reward': 0.12287,\n",
       "   'episode_length': 185.52513549804686,\n",
       "   'normalised_reward': -0.00044198483794927597}},\n",
       " 6406: {'stats': {'sameRoom': 13998,\n",
       "   'agentInRoomID0': 13837,\n",
       "   'agentInRoomID1': 14006,\n",
       "   'targetInRoomID0': 14020,\n",
       "   'targetInRoomID1': 13823,\n",
       "   'episodeCount': 27843,\n",
       "   'sensorCount': 32,\n",
       "   'runId': 6406,\n",
       "   'targetRoomIndex0': 14020,\n",
       "   'targetRoomIndex1': 13823},\n",
       "  'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6406,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6406_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}},\n",
       "  'result': {'mean_reward': -0.3424353305622935,\n",
       "   'std_mean_reward': 0.13533,\n",
       "   'episode_length': 173.2276739501953,\n",
       "   'normalised_reward': -0.0003424353305622935}},\n",
       " 6183: {'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6183,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6183_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 356,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}}},\n",
       " 6203: {'unity_config': {'sensorCount': 32,\n",
       "   'useDecoy': False,\n",
       "   'createWall': True,\n",
       "   'doorWidth': 4.0,\n",
       "   'randomWallPosition': True,\n",
       "   'randomDoorPosition': True,\n",
       "   'targetAlwaysInOtherRoomFromAgent': False,\n",
       "   'targetFixedPosition': False,\n",
       "   'maxStep': 1000,\n",
       "   'stepPenalty': -0.0005,\n",
       "   'runId': 6203,\n",
       "   'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6203_stats.json'},\n",
       "  'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "      'beta': '1e-2',\n",
       "      'buffer_size': 51200,\n",
       "      'epsilon': 0.2,\n",
       "      'lambd': 0.95,\n",
       "      'learning_rate': '1e-3',\n",
       "      'learning_rate_schedule': 'linear',\n",
       "      'num_epoch': 3},\n",
       "     'keep_checkpoints': 5,\n",
       "     'max_steps': '5e6',\n",
       "     'network_settings': {'conditioning_type': 'none',\n",
       "      'hidden_units': 512,\n",
       "      'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "      'normalize': False,\n",
       "      'num_layers': 1},\n",
       "     'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "     'summary_freq': 10000,\n",
       "     'time_horizon': 2000,\n",
       "     'trainer_type': 'ppo'}}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ids_dict = {}\n",
    "for run_id in selected_ids:\n",
    "    selected_ids_dict[run_id] = {}\n",
    "\n",
    "    if \"stats_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"stats_dir\"]) as json_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"stats\"] = json.load(json_file)\n",
    "    \n",
    "    if \"unity_configs_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"unity_configs_dir\"]) as json_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"unity_config\"] = json.load(json_file)\n",
    "\n",
    "    if \"configs_dir\" in run_dict[run_id]:\n",
    "        with open(run_dict[run_id][\"configs_dir\"]) as yaml_file:\n",
    "        #results[\"stats\"] = json.load(json_file)\n",
    "            selected_ids_dict[run_id][\"training_config\"] = yaml.safe_load(yaml_file)\n",
    "    \n",
    "    if \"results_dir\" in run_dict[run_id]:\n",
    "        selected_ids_dict[run_id][\"result\"] = get_result_overview(run_dict[run_id][\"results_dir\"], selected_ids_dict[run_id][\"unity_config\"])\n",
    "\n",
    "\n",
    "selected_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unity_config': {'sensorCount': 32,\n",
       "  'useDecoy': False,\n",
       "  'createWall': True,\n",
       "  'doorWidth': 4.0,\n",
       "  'randomWallPosition': True,\n",
       "  'randomDoorPosition': True,\n",
       "  'targetAlwaysInOtherRoomFromAgent': False,\n",
       "  'targetFixedPosition': False,\n",
       "  'maxStep': 1000,\n",
       "  'stepPenalty': -0.0005,\n",
       "  'runId': 6183,\n",
       "  'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6183_stats.json'},\n",
       " 'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "     'beta': '1e-2',\n",
       "     'buffer_size': 51200,\n",
       "     'epsilon': 0.2,\n",
       "     'lambd': 0.95,\n",
       "     'learning_rate': '1e-3',\n",
       "     'learning_rate_schedule': 'linear',\n",
       "     'num_epoch': 3},\n",
       "    'keep_checkpoints': 5,\n",
       "    'max_steps': '5e6',\n",
       "    'network_settings': {'conditioning_type': 'none',\n",
       "     'hidden_units': 356,\n",
       "     'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "     'normalize': False,\n",
       "     'num_layers': 1},\n",
       "    'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "    'summary_freq': 10000,\n",
       "    'time_horizon': 2000,\n",
       "    'trainer_type': 'ppo'}}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected_ids_dict[6183]p.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ids from the dict if no result in dict saved.\n",
    "problem_ids = []\n",
    "for entry in selected_ids_dict:\n",
    "    if \"result\" not in selected_ids_dict[entry]:\n",
    "        problem_ids.append(entry)\n",
    "\n",
    "for id in problem_ids:\n",
    "    selected_ids_dict.pop(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(6202,\n",
       "              {'stats': {'sameRoom': 14916,\n",
       "                'agentInRoomID0': 14919,\n",
       "                'agentInRoomID1': 14909,\n",
       "                'targetInRoomID0': 14927,\n",
       "                'targetInRoomID1': 14901,\n",
       "                'episodeCount': 29828,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6202,\n",
       "                'targetRoomIndex0': 14927,\n",
       "                'targetRoomIndex1': 14901},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6202,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6202_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.13076711568748578,\n",
       "                'std_mean_reward': 0.14214,\n",
       "                'episode_length': 154.391163482666,\n",
       "                'normalised_reward': -0.00013076711568748577}}),\n",
       "             (6293,\n",
       "              {'stats': {'sameRoom': 14492,\n",
       "                'agentInRoomID0': 14449,\n",
       "                'agentInRoomID1': 14399,\n",
       "                'targetInRoomID0': 14353,\n",
       "                'targetInRoomID1': 14495,\n",
       "                'episodeCount': 28848,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6293,\n",
       "                'targetRoomIndex0': 14353,\n",
       "                'targetRoomIndex1': 14495},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6293,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6293_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.17947203435003758,\n",
       "                'std_mean_reward': 0.1504,\n",
       "                'episode_length': 158.98133239746093,\n",
       "                'normalised_reward': -0.0001794720343500376}}),\n",
       "             (6268,\n",
       "              {'stats': {'sameRoom': 14345,\n",
       "                'agentInRoomID0': 14395,\n",
       "                'agentInRoomID1': 14231,\n",
       "                'targetInRoomID0': 14286,\n",
       "                'targetInRoomID1': 14340,\n",
       "                'episodeCount': 28626,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6268,\n",
       "                'targetRoomIndex0': 14286,\n",
       "                'targetRoomIndex1': 14340},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6268,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6268_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.20502461072057485,\n",
       "                'std_mean_reward': 0.10139,\n",
       "                'episode_length': 163.77803817749023,\n",
       "                'normalised_reward': -0.00020502461072057485}}),\n",
       "             (6235,\n",
       "              {'stats': {'sameRoom': 14232,\n",
       "                'agentInRoomID0': 14220,\n",
       "                'agentInRoomID1': 14198,\n",
       "                'targetInRoomID0': 14108,\n",
       "                'targetInRoomID1': 14310,\n",
       "                'episodeCount': 28418,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6235,\n",
       "                'targetRoomIndex0': 14108,\n",
       "                'targetRoomIndex1': 14310},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6235,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6235_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.20758897423744202,\n",
       "                'std_mean_reward': 0.10909,\n",
       "                'episode_length': 165.29003479003907,\n",
       "                'normalised_reward': -0.00020758897423744203}}),\n",
       "             (6191,\n",
       "              {'stats': {'sameRoom': 14524,\n",
       "                'agentInRoomID0': 14476,\n",
       "                'agentInRoomID1': 14501,\n",
       "                'targetInRoomID0': 14527,\n",
       "                'targetInRoomID1': 14450,\n",
       "                'episodeCount': 28977,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6191,\n",
       "                'targetRoomIndex0': 14527,\n",
       "                'targetRoomIndex1': 14450},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6191,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6191_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.20882328735664488,\n",
       "                'std_mean_reward': 0.13161,\n",
       "                'episode_length': 162.9525895690918,\n",
       "                'normalised_reward': -0.00020882328735664487}}),\n",
       "             (6276,\n",
       "              {'stats': {'sameRoom': 14279,\n",
       "                'agentInRoomID0': 14311,\n",
       "                'agentInRoomID1': 14261,\n",
       "                'targetInRoomID0': 14256,\n",
       "                'targetInRoomID1': 14316,\n",
       "                'episodeCount': 28572,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6276,\n",
       "                'targetRoomIndex0': 14256,\n",
       "                'targetRoomIndex1': 14316},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6276,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6276_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.20926464358344674,\n",
       "                'std_mean_reward': 0.10375,\n",
       "                'episode_length': 165.83152282714843,\n",
       "                'normalised_reward': -0.00020926464358344673}}),\n",
       "             (6230,\n",
       "              {'stats': {'sameRoom': 14641,\n",
       "                'agentInRoomID0': 14449,\n",
       "                'agentInRoomID1': 14435,\n",
       "                'targetInRoomID0': 14418,\n",
       "                'targetInRoomID1': 14466,\n",
       "                'episodeCount': 28884,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6230,\n",
       "                'targetRoomIndex0': 14418,\n",
       "                'targetRoomIndex1': 14466},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6230,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6230_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.22329374431166799,\n",
       "                'std_mean_reward': 0.1162,\n",
       "                'episode_length': 164.266328125,\n",
       "                'normalised_reward': -0.000223293744311668}}),\n",
       "             (6181,\n",
       "              {'stats': {'sameRoom': 14411,\n",
       "                'agentInRoomID0': 14237,\n",
       "                'agentInRoomID1': 14532,\n",
       "                'targetInRoomID0': 14457,\n",
       "                'targetInRoomID1': 14312,\n",
       "                'episodeCount': 28769,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6181,\n",
       "                'targetRoomIndex0': 14457,\n",
       "                'targetRoomIndex1': 14312},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6181,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6181_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2304030789155513,\n",
       "                'std_mean_reward': 0.12548,\n",
       "                'episode_length': 166.03373168945313,\n",
       "                'normalised_reward': -0.00023040307891555132}}),\n",
       "             (6291,\n",
       "              {'stats': {'sameRoom': 14359,\n",
       "                'agentInRoomID0': 14250,\n",
       "                'agentInRoomID1': 14456,\n",
       "                'targetInRoomID0': 14411,\n",
       "                'targetInRoomID1': 14295,\n",
       "                'episodeCount': 28706,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6291,\n",
       "                'targetRoomIndex0': 14411,\n",
       "                'targetRoomIndex1': 14295},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6291,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6291_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2343151248033246,\n",
       "                'std_mean_reward': 0.12082,\n",
       "                'episode_length': 163.10093948364258,\n",
       "                'normalised_reward': -0.0002343151248033246}}),\n",
       "             (6241,\n",
       "              {'stats': {'sameRoom': 14215,\n",
       "                'agentInRoomID0': 14196,\n",
       "                'agentInRoomID1': 14214,\n",
       "                'targetInRoomID0': 14183,\n",
       "                'targetInRoomID1': 14227,\n",
       "                'episodeCount': 28410,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6241,\n",
       "                'targetRoomIndex0': 14183,\n",
       "                'targetRoomIndex1': 14227},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6241,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6241_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2361103981602355,\n",
       "                'std_mean_reward': 0.15887,\n",
       "                'episode_length': 163.8843295288086,\n",
       "                'normalised_reward': -0.00023611039816023548}}),\n",
       "             (6195,\n",
       "              {'stats': {'sameRoom': 14633,\n",
       "                'agentInRoomID0': 14545,\n",
       "                'agentInRoomID1': 14408,\n",
       "                'targetInRoomID0': 14465,\n",
       "                'targetInRoomID1': 14488,\n",
       "                'episodeCount': 28953,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6195,\n",
       "                'targetRoomIndex0': 14465,\n",
       "                'targetRoomIndex1': 14488},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6195,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6195_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2371140659181401,\n",
       "                'std_mean_reward': 0.13689,\n",
       "                'episode_length': 163.54295333862305,\n",
       "                'normalised_reward': -0.0002371140659181401}}),\n",
       "             (6306,\n",
       "              {'stats': {'sameRoom': 14329,\n",
       "                'agentInRoomID0': 14358,\n",
       "                'agentInRoomID1': 14265,\n",
       "                'targetInRoomID0': 14316,\n",
       "                'targetInRoomID1': 14307,\n",
       "                'episodeCount': 28623,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6306,\n",
       "                'targetRoomIndex0': 14316,\n",
       "                'targetRoomIndex1': 14307},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6306,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6306_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2454745088145137,\n",
       "                'std_mean_reward': 0.11366,\n",
       "                'episode_length': 166.9709635925293,\n",
       "                'normalised_reward': -0.00024547450881451366}}),\n",
       "             (6326,\n",
       "              {'stats': {'sameRoom': 69,\n",
       "                'agentInRoomID0': 72,\n",
       "                'agentInRoomID1': 60,\n",
       "                'targetInRoomID0': 67,\n",
       "                'targetInRoomID1': 65,\n",
       "                'episodeCount': 132,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6326,\n",
       "                'targetRoomIndex0': 67,\n",
       "                'targetRoomIndex1': 65},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6326,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6326_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': nan,\n",
       "                'std_mean_reward': nan,\n",
       "                'episode_length': nan,\n",
       "                'normalised_reward': nan}}),\n",
       "             (6351,\n",
       "              {'stats': {'sameRoom': 14219,\n",
       "                'agentInRoomID0': 14103,\n",
       "                'agentInRoomID1': 14334,\n",
       "                'targetInRoomID0': 14207,\n",
       "                'targetInRoomID1': 14230,\n",
       "                'episodeCount': 28437,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6351,\n",
       "                'targetRoomIndex0': 14207,\n",
       "                'targetRoomIndex1': 14230},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6351,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6351_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.23950779225677252,\n",
       "                'std_mean_reward': 0.12799,\n",
       "                'episode_length': 167.17878845214844,\n",
       "                'normalised_reward': -0.00023950779225677252}}),\n",
       "             (6328,\n",
       "              {'stats': {'sameRoom': 14036,\n",
       "                'agentInRoomID0': 13918,\n",
       "                'agentInRoomID1': 14206,\n",
       "                'targetInRoomID0': 14028,\n",
       "                'targetInRoomID1': 14096,\n",
       "                'episodeCount': 28124,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6328,\n",
       "                'targetRoomIndex0': 14028,\n",
       "                'targetRoomIndex1': 14096},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6328,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6328_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.24723626595921813,\n",
       "                'std_mean_reward': 0.11161,\n",
       "                'episode_length': 167.85951873779297,\n",
       "                'normalised_reward': -0.00024723626595921815}}),\n",
       "             (6297,\n",
       "              {'stats': {'sameRoom': 14241,\n",
       "                'agentInRoomID0': 14166,\n",
       "                'agentInRoomID1': 14230,\n",
       "                'targetInRoomID0': 14187,\n",
       "                'targetInRoomID1': 14209,\n",
       "                'episodeCount': 28396,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6297,\n",
       "                'targetRoomIndex0': 14187,\n",
       "                'targetRoomIndex1': 14209},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6297,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6297_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.248363663807977,\n",
       "                'std_mean_reward': 0.1542,\n",
       "                'episode_length': 167.23421813964845,\n",
       "                'normalised_reward': -0.000248363663807977}}),\n",
       "             (6373,\n",
       "              {'stats': {'sameRoom': 13960,\n",
       "                'agentInRoomID0': 13834,\n",
       "                'agentInRoomID1': 14115,\n",
       "                'targetInRoomID0': 13965,\n",
       "                'targetInRoomID1': 13984,\n",
       "                'episodeCount': 27949,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6373,\n",
       "                'targetRoomIndex0': 13965,\n",
       "                'targetRoomIndex1': 13984},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6373,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6373_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.25447233198210595,\n",
       "                'std_mean_reward': 0.1113,\n",
       "                'episode_length': 166.79032577514647,\n",
       "                'normalised_reward': -0.0002544723319821059}}),\n",
       "             (6190,\n",
       "              {'stats': {'sameRoom': 14203,\n",
       "                'agentInRoomID0': 14281,\n",
       "                'agentInRoomID1': 14045,\n",
       "                'targetInRoomID0': 14202,\n",
       "                'targetInRoomID1': 14124,\n",
       "                'episodeCount': 28326,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6190,\n",
       "                'targetRoomIndex0': 14202,\n",
       "                'targetRoomIndex1': 14124},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6190,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6190_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.25859064191579817,\n",
       "                'std_mean_reward': 0.11902,\n",
       "                'episode_length': 167.7788700866699,\n",
       "                'normalised_reward': -0.0002585906419157982}}),\n",
       "             (6323,\n",
       "              {'stats': {'sameRoom': 14313,\n",
       "                'agentInRoomID0': 14252,\n",
       "                'agentInRoomID1': 14233,\n",
       "                'targetInRoomID0': 14340,\n",
       "                'targetInRoomID1': 14145,\n",
       "                'episodeCount': 28485,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6323,\n",
       "                'targetRoomIndex0': 14340,\n",
       "                'targetRoomIndex1': 14145},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6323,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6323_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2602912992425263,\n",
       "                'std_mean_reward': 0.10913,\n",
       "                'episode_length': 167.82647537231446,\n",
       "                'normalised_reward': -0.0002602912992425263}}),\n",
       "             (6303,\n",
       "              {'stats': {'sameRoom': 14049,\n",
       "                'agentInRoomID0': 14190,\n",
       "                'agentInRoomID1': 13910,\n",
       "                'targetInRoomID0': 13953,\n",
       "                'targetInRoomID1': 14147,\n",
       "                'episodeCount': 28100,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6303,\n",
       "                'targetRoomIndex0': 13953,\n",
       "                'targetRoomIndex1': 14147},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6303,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6303_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.26092289347201586,\n",
       "                'std_mean_reward': 0.1062,\n",
       "                'episode_length': 168.48914947509766,\n",
       "                'normalised_reward': -0.00026092289347201585}}),\n",
       "             (6353,\n",
       "              {'stats': {'sameRoom': 13794,\n",
       "                'agentInRoomID0': 13790,\n",
       "                'agentInRoomID1': 13877,\n",
       "                'targetInRoomID0': 13811,\n",
       "                'targetInRoomID1': 13856,\n",
       "                'episodeCount': 27667,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6353,\n",
       "                'targetRoomIndex0': 13811,\n",
       "                'targetRoomIndex1': 13856},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6353,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6353_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2648521926254034,\n",
       "                'std_mean_reward': 0.11491,\n",
       "                'episode_length': 170.51665618896484,\n",
       "                'normalised_reward': -0.00026485219262540336}}),\n",
       "             (6245,\n",
       "              {'stats': {'sameRoom': 14257,\n",
       "                'agentInRoomID0': 14114,\n",
       "                'agentInRoomID1': 14471,\n",
       "                'targetInRoomID0': 14204,\n",
       "                'targetInRoomID1': 14381,\n",
       "                'episodeCount': 28585,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6245,\n",
       "                'targetRoomIndex0': 14204,\n",
       "                'targetRoomIndex1': 14381},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6245,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6245_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2668987016007304,\n",
       "                'std_mean_reward': 0.12063,\n",
       "                'episode_length': 165.6969137573242,\n",
       "                'normalised_reward': -0.0002668987016007304}}),\n",
       "             (6251,\n",
       "              {'stats': {'sameRoom': 14135,\n",
       "                'agentInRoomID0': 14026,\n",
       "                'agentInRoomID1': 14319,\n",
       "                'targetInRoomID0': 14144,\n",
       "                'targetInRoomID1': 14201,\n",
       "                'episodeCount': 28345,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6251,\n",
       "                'targetRoomIndex0': 14144,\n",
       "                'targetRoomIndex1': 14201},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6251,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6251_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2686461552232504,\n",
       "                'std_mean_reward': 0.12148,\n",
       "                'episode_length': 168.59771713256836,\n",
       "                'normalised_reward': -0.0002686461552232504}}),\n",
       "             (6378,\n",
       "              {'stats': {'sameRoom': 13712,\n",
       "                'agentInRoomID0': 13746,\n",
       "                'agentInRoomID1': 13871,\n",
       "                'targetInRoomID0': 13571,\n",
       "                'targetInRoomID1': 14046,\n",
       "                'episodeCount': 27617,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6378,\n",
       "                'targetRoomIndex0': 13571,\n",
       "                'targetRoomIndex1': 14046},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6378,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6378_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.27425402622669937,\n",
       "                'std_mean_reward': 0.11976,\n",
       "                'episode_length': 169.69782363891602,\n",
       "                'normalised_reward': -0.00027425402622669934}}),\n",
       "             (6398,\n",
       "              {'stats': {'sameRoom': 13865,\n",
       "                'agentInRoomID0': 13782,\n",
       "                'agentInRoomID1': 13870,\n",
       "                'targetInRoomID0': 13781,\n",
       "                'targetInRoomID1': 13871,\n",
       "                'episodeCount': 27652,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6398,\n",
       "                'targetRoomIndex0': 13781,\n",
       "                'targetRoomIndex1': 13871},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6398,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6398_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2761340121179819,\n",
       "                'std_mean_reward': 0.11775,\n",
       "                'episode_length': 170.3212809753418,\n",
       "                'normalised_reward': -0.0002761340121179819}}),\n",
       "             (6271,\n",
       "              {'stats': {'sameRoom': 14115,\n",
       "                'agentInRoomID0': 14047,\n",
       "                'agentInRoomID1': 14041,\n",
       "                'targetInRoomID0': 13986,\n",
       "                'targetInRoomID1': 14102,\n",
       "                'episodeCount': 28088,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6271,\n",
       "                'targetRoomIndex0': 13986,\n",
       "                'targetRoomIndex1': 14102},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6271,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6271_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.28226251363754273,\n",
       "                'std_mean_reward': 0.11132,\n",
       "                'episode_length': 168.906513671875,\n",
       "                'normalised_reward': -0.00028226251363754274}}),\n",
       "             (6299,\n",
       "              {'stats': {'sameRoom': 14302,\n",
       "                'agentInRoomID0': 14205,\n",
       "                'agentInRoomID1': 14373,\n",
       "                'targetInRoomID0': 14279,\n",
       "                'targetInRoomID1': 14299,\n",
       "                'episodeCount': 28578,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6299,\n",
       "                'targetRoomIndex0': 14279,\n",
       "                'targetRoomIndex1': 14299},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6299,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6299_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.2832967826165259,\n",
       "                'std_mean_reward': 0.14676,\n",
       "                'episode_length': 163.51846649169923,\n",
       "                'normalised_reward': -0.0002832967826165259}}),\n",
       "             (6400,\n",
       "              {'stats': {'sameRoom': 14179,\n",
       "                'agentInRoomID0': 14008,\n",
       "                'agentInRoomID1': 14320,\n",
       "                'targetInRoomID0': 14149,\n",
       "                'targetInRoomID1': 14179,\n",
       "                'episodeCount': 28328,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6400,\n",
       "                'targetRoomIndex0': 14149,\n",
       "                'targetRoomIndex1': 14179},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6400,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6400_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.292469427511096,\n",
       "                'std_mean_reward': 0.13854,\n",
       "                'episode_length': 167.16640258789062,\n",
       "                'normalised_reward': -0.000292469427511096}}),\n",
       "             (6309,\n",
       "              {'stats': {'sameRoom': 13891,\n",
       "                'agentInRoomID0': 14058,\n",
       "                'agentInRoomID1': 13824,\n",
       "                'targetInRoomID0': 13959,\n",
       "                'targetInRoomID1': 13923,\n",
       "                'episodeCount': 27882,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6309,\n",
       "                'targetRoomIndex0': 13959,\n",
       "                'targetRoomIndex1': 13923},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6309,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6309_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.29826728712767364,\n",
       "                'std_mean_reward': 0.14118,\n",
       "                'episode_length': 170.6179753112793,\n",
       "                'normalised_reward': -0.00029826728712767364}}),\n",
       "             (6247,\n",
       "              {'stats': {'sameRoom': 13813,\n",
       "                'agentInRoomID0': 13932,\n",
       "                'agentInRoomID1': 14020,\n",
       "                'targetInRoomID0': 14077,\n",
       "                'targetInRoomID1': 13875,\n",
       "                'episodeCount': 27952,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6247,\n",
       "                'targetRoomIndex0': 14077,\n",
       "                'targetRoomIndex1': 13875},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6247,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6247_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3009951530396938,\n",
       "                'std_mean_reward': 0.11029,\n",
       "                'episode_length': 174.37648803710937,\n",
       "                'normalised_reward': -0.0003009951530396938}}),\n",
       "             (6371,\n",
       "              {'stats': {'sameRoom': 13820,\n",
       "                'agentInRoomID0': 13775,\n",
       "                'agentInRoomID1': 13628,\n",
       "                'targetInRoomID0': 13726,\n",
       "                'targetInRoomID1': 13677,\n",
       "                'episodeCount': 27403,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6371,\n",
       "                'targetRoomIndex0': 13726,\n",
       "                'targetRoomIndex1': 13677},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6371,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6371_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.30259506825357674,\n",
       "                'std_mean_reward': 0.11411,\n",
       "                'episode_length': 174.54285263061524,\n",
       "                'normalised_reward': -0.00030259506825357674}}),\n",
       "             (6286,\n",
       "              {'stats': {'sameRoom': 14035,\n",
       "                'agentInRoomID0': 14083,\n",
       "                'agentInRoomID1': 14023,\n",
       "                'targetInRoomID0': 14054,\n",
       "                'targetInRoomID1': 14052,\n",
       "                'episodeCount': 28106,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6286,\n",
       "                'targetRoomIndex0': 14054,\n",
       "                'targetRoomIndex1': 14052},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6286,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6286_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.30389424227178097,\n",
       "                'std_mean_reward': 0.1109,\n",
       "                'episode_length': 173.1688494873047,\n",
       "                'normalised_reward': -0.00030389424227178095}}),\n",
       "             (6397,\n",
       "              {'stats': {'sameRoom': 13614,\n",
       "                'agentInRoomID0': 13698,\n",
       "                'agentInRoomID1': 13662,\n",
       "                'targetInRoomID0': 13856,\n",
       "                'targetInRoomID1': 13504,\n",
       "                'episodeCount': 27360,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6397,\n",
       "                'targetRoomIndex0': 13856,\n",
       "                'targetRoomIndex1': 13504},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6397,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6397_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.30523468628525735,\n",
       "                'std_mean_reward': 0.12182,\n",
       "                'episode_length': 173.30019439697264,\n",
       "                'normalised_reward': -0.00030523468628525734}}),\n",
       "             (6239,\n",
       "              {'stats': {'sameRoom': 14614,\n",
       "                'agentInRoomID0': 14307,\n",
       "                'agentInRoomID1': 14529,\n",
       "                'targetInRoomID0': 14467,\n",
       "                'targetInRoomID1': 14369,\n",
       "                'episodeCount': 28836,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6239,\n",
       "                'targetRoomIndex0': 14467,\n",
       "                'targetRoomIndex1': 14369},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6239,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6239_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3106884836498648,\n",
       "                'std_mean_reward': 0.15953,\n",
       "                'episode_length': 168.05660461425782,\n",
       "                'normalised_reward': -0.0003106884836498648}}),\n",
       "             (6344,\n",
       "              {'stats': {'sameRoom': 14080,\n",
       "                'agentInRoomID0': 14021,\n",
       "                'agentInRoomID1': 13994,\n",
       "                'targetInRoomID0': 13958,\n",
       "                'targetInRoomID1': 14057,\n",
       "                'episodeCount': 28015,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6344,\n",
       "                'targetRoomIndex0': 13958,\n",
       "                'targetRoomIndex1': 14057},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6344,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6344_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.31808342412114143,\n",
       "                'std_mean_reward': 0.14048,\n",
       "                'episode_length': 171.48535690307617,\n",
       "                'normalised_reward': -0.00031808342412114146}}),\n",
       "             (6367,\n",
       "              {'stats': {'sameRoom': 13692,\n",
       "                'agentInRoomID0': 13713,\n",
       "                'agentInRoomID1': 13700,\n",
       "                'targetInRoomID0': 13564,\n",
       "                'targetInRoomID1': 13849,\n",
       "                'episodeCount': 27413,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6367,\n",
       "                'targetRoomIndex0': 13564,\n",
       "                'targetRoomIndex1': 13849},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6367,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6367_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.32023403123021127,\n",
       "                'std_mean_reward': 0.11171,\n",
       "                'episode_length': 173.24710708618164,\n",
       "                'normalised_reward': -0.00032023403123021126}}),\n",
       "             (6339,\n",
       "              {'stats': {'sameRoom': 14131,\n",
       "                'agentInRoomID0': 13986,\n",
       "                'agentInRoomID1': 14025,\n",
       "                'targetInRoomID0': 14042,\n",
       "                'targetInRoomID1': 13969,\n",
       "                'episodeCount': 28011,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6339,\n",
       "                'targetRoomIndex0': 14042,\n",
       "                'targetRoomIndex1': 13969},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6339,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6339_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.323274797424674,\n",
       "                'std_mean_reward': 0.12291,\n",
       "                'episode_length': 170.8819445800781,\n",
       "                'normalised_reward': -0.000323274797424674}}),\n",
       "             (6330,\n",
       "              {'stats': {'sameRoom': 13994,\n",
       "                'agentInRoomID0': 13986,\n",
       "                'agentInRoomID1': 13966,\n",
       "                'targetInRoomID0': 13834,\n",
       "                'targetInRoomID1': 14118,\n",
       "                'episodeCount': 27952,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6330,\n",
       "                'targetRoomIndex0': 13834,\n",
       "                'targetRoomIndex1': 14118},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6330,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6330_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 128,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.32580278903245924,\n",
       "                'std_mean_reward': 0.13219,\n",
       "                'episode_length': 171.3531185913086,\n",
       "                'normalised_reward': -0.00032580278903245925}}),\n",
       "             (6249,\n",
       "              {'stats': {'sameRoom': 14038,\n",
       "                'agentInRoomID0': 13883,\n",
       "                'agentInRoomID1': 14208,\n",
       "                'targetInRoomID0': 14052,\n",
       "                'targetInRoomID1': 14039,\n",
       "                'episodeCount': 28091,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6249,\n",
       "                'targetRoomIndex0': 14052,\n",
       "                'targetRoomIndex1': 14039},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6249,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6249_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 32,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 64, 'sequence_length': 2},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3292365188896656,\n",
       "                'std_mean_reward': 0.12103,\n",
       "                'episode_length': 172.63443984985352,\n",
       "                'normalised_reward': -0.0003292365188896656}}),\n",
       "             (6406,\n",
       "              {'stats': {'sameRoom': 13998,\n",
       "                'agentInRoomID0': 13837,\n",
       "                'agentInRoomID1': 14006,\n",
       "                'targetInRoomID0': 14020,\n",
       "                'targetInRoomID1': 13823,\n",
       "                'episodeCount': 27843,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6406,\n",
       "                'targetRoomIndex0': 14020,\n",
       "                'targetRoomIndex1': 13823},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6406,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6406_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 8},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3424353305622935,\n",
       "                'std_mean_reward': 0.13533,\n",
       "                'episode_length': 173.2276739501953,\n",
       "                'normalised_reward': -0.0003424353305622935}}),\n",
       "             (6345,\n",
       "              {'stats': {'sameRoom': 13825,\n",
       "                'agentInRoomID0': 13827,\n",
       "                'agentInRoomID1': 13827,\n",
       "                'targetInRoomID0': 13894,\n",
       "                'targetInRoomID1': 13760,\n",
       "                'episodeCount': 27654,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6345,\n",
       "                'targetRoomIndex0': 13894,\n",
       "                'targetRoomIndex1': 13760},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6345,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6345_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.34842287011444567,\n",
       "                'std_mean_reward': 0.1582,\n",
       "                'episode_length': 173.005223236084,\n",
       "                'normalised_reward': -0.0003484228701144457}}),\n",
       "             (6402,\n",
       "              {'stats': {'sameRoom': 13637,\n",
       "                'agentInRoomID0': 13714,\n",
       "                'agentInRoomID1': 13775,\n",
       "                'targetInRoomID0': 13618,\n",
       "                'targetInRoomID1': 13871,\n",
       "                'episodeCount': 27489,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6402,\n",
       "                'targetRoomIndex0': 13618,\n",
       "                'targetRoomIndex1': 13871},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6402,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6402_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3485051322728395,\n",
       "                'std_mean_reward': 0.12221,\n",
       "                'episode_length': 174.90239685058594,\n",
       "                'normalised_reward': -0.00034850513227283953}}),\n",
       "             (6375,\n",
       "              {'stats': {'sameRoom': 13647,\n",
       "                'agentInRoomID0': 13672,\n",
       "                'agentInRoomID1': 13478,\n",
       "                'targetInRoomID0': 13637,\n",
       "                'targetInRoomID1': 13513,\n",
       "                'episodeCount': 27150,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6375,\n",
       "                'targetRoomIndex0': 13637,\n",
       "                'targetRoomIndex1': 13513},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6375,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6375_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3574017135798931,\n",
       "                'std_mean_reward': 0.10498,\n",
       "                'episode_length': 178.83748657226562,\n",
       "                'normalised_reward': -0.00035740171357989307}}),\n",
       "             (6387,\n",
       "              {'stats': {'sameRoom': 13512,\n",
       "                'agentInRoomID0': 13685,\n",
       "                'agentInRoomID1': 13658,\n",
       "                'targetInRoomID0': 13600,\n",
       "                'targetInRoomID1': 13743,\n",
       "                'episodeCount': 27343,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6387,\n",
       "                'targetRoomIndex0': 13600,\n",
       "                'targetRoomIndex1': 13743},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6387,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6387_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 16},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.3602246770262718,\n",
       "                'std_mean_reward': 0.16931,\n",
       "                'episode_length': 175.1582518005371,\n",
       "                'normalised_reward': -0.0003602246770262718}}),\n",
       "             (6363,\n",
       "              {'stats': {'sameRoom': 13926,\n",
       "                'agentInRoomID0': 13771,\n",
       "                'agentInRoomID1': 13766,\n",
       "                'targetInRoomID0': 13728,\n",
       "                'targetInRoomID1': 13809,\n",
       "                'episodeCount': 27537,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6363,\n",
       "                'targetRoomIndex0': 13728,\n",
       "                'targetRoomIndex1': 13809},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6363,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6363_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 356,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 16, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.36264205232262614,\n",
       "                'std_mean_reward': 0.12673,\n",
       "                'episode_length': 175.55774139404298,\n",
       "                'normalised_reward': -0.00036264205232262615}}),\n",
       "             (6405,\n",
       "              {'stats': {'sameRoom': 13158,\n",
       "                'agentInRoomID0': 13411,\n",
       "                'agentInRoomID1': 13221,\n",
       "                'targetInRoomID0': 13371,\n",
       "                'targetInRoomID1': 13261,\n",
       "                'episodeCount': 26632,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6405,\n",
       "                'targetRoomIndex0': 13371,\n",
       "                'targetRoomIndex1': 13261},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6405,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6405_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 512,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 512,\n",
       "                   'memory': {'memory_size': 32, 'sequence_length': 4},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.44198483794927595,\n",
       "                'std_mean_reward': 0.12287,\n",
       "                'episode_length': 185.52513549804686,\n",
       "                'normalised_reward': -0.00044198483794927597}}),\n",
       "             (6278,\n",
       "              {'stats': {'sameRoom': 5139,\n",
       "                'agentInRoomID0': 5157,\n",
       "                'agentInRoomID1': 5059,\n",
       "                'targetInRoomID0': 5106,\n",
       "                'targetInRoomID1': 5110,\n",
       "                'episodeCount': 10216,\n",
       "                'sensorCount': 32,\n",
       "                'runId': 6278,\n",
       "                'targetRoomIndex0': 5106,\n",
       "                'targetRoomIndex1': 5110},\n",
       "               'unity_config': {'sensorCount': 32,\n",
       "                'useDecoy': False,\n",
       "                'createWall': True,\n",
       "                'doorWidth': 4.0,\n",
       "                'randomWallPosition': True,\n",
       "                'randomDoorPosition': True,\n",
       "                'targetAlwaysInOtherRoomFromAgent': False,\n",
       "                'targetFixedPosition': False,\n",
       "                'maxStep': 1000,\n",
       "                'stepPenalty': -0.0005,\n",
       "                'runId': 6278,\n",
       "                'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6278_stats.json'},\n",
       "               'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 64,\n",
       "                   'beta': '1e-2',\n",
       "                   'buffer_size': 51200,\n",
       "                   'epsilon': 0.2,\n",
       "                   'lambd': 0.95,\n",
       "                   'learning_rate': '1e-3',\n",
       "                   'learning_rate_schedule': 'linear',\n",
       "                   'num_epoch': 3},\n",
       "                  'keep_checkpoints': 5,\n",
       "                  'max_steps': '5e6',\n",
       "                  'network_settings': {'conditioning_type': 'none',\n",
       "                   'hidden_units': 356,\n",
       "                   'memory': {'memory_size': 128, 'sequence_length': 32},\n",
       "                   'normalize': False,\n",
       "                   'num_layers': 1},\n",
       "                  'reward_signals': {'extrinsic': {'gamma': 0.99,\n",
       "                    'strength': 1.0}},\n",
       "                  'summary_freq': 10000,\n",
       "                  'time_horizon': 2000,\n",
       "                  'trainer_type': 'ppo'}}},\n",
       "               'result': {'mean_reward': -0.6078064243495465,\n",
       "                'std_mean_reward': 0.26618,\n",
       "                'episode_length': 179.78206909179687,\n",
       "                'normalised_reward': -0.0006078064243495465}})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict = OrderedDict(\n",
    "            sorted(\n",
    "                selected_ids_dict.items(), key=lambda v: v[1][\"result\"][\"mean_reward\"], reverse=True\n",
    "            )\n",
    "        )\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stats': {'sameRoom': 14916,\n",
       "  'agentInRoomID0': 14919,\n",
       "  'agentInRoomID1': 14909,\n",
       "  'targetInRoomID0': 14927,\n",
       "  'targetInRoomID1': 14901,\n",
       "  'episodeCount': 29828,\n",
       "  'sensorCount': 32,\n",
       "  'runId': 6202,\n",
       "  'targetRoomIndex0': 14927,\n",
       "  'targetRoomIndex1': 14901},\n",
       " 'unity_config': {'sensorCount': 32,\n",
       "  'useDecoy': False,\n",
       "  'createWall': True,\n",
       "  'doorWidth': 4.0,\n",
       "  'randomWallPosition': True,\n",
       "  'randomDoorPosition': True,\n",
       "  'targetAlwaysInOtherRoomFromAgent': False,\n",
       "  'targetFixedPosition': False,\n",
       "  'maxStep': 1000,\n",
       "  'stepPenalty': -0.0005,\n",
       "  'runId': 6202,\n",
       "  'statsExportPath': 'C:\\\\Users\\\\max.muehlefeldt\\\\Documents\\\\GitHub\\\\unity-machine-learning\\\\python\\\\basic_rl_env\\\\stats\\\\6202_stats.json'},\n",
       " 'training_config': {'behaviors': {'RollerAgent': {'hyperparameters': {'batch_size': 16,\n",
       "     'beta': '1e-2',\n",
       "     'buffer_size': 51200,\n",
       "     'epsilon': 0.2,\n",
       "     'lambd': 0.95,\n",
       "     'learning_rate': '1e-3',\n",
       "     'learning_rate_schedule': 'linear',\n",
       "     'num_epoch': 3},\n",
       "    'keep_checkpoints': 5,\n",
       "    'max_steps': '5e6',\n",
       "    'network_settings': {'conditioning_type': 'none',\n",
       "     'hidden_units': 512,\n",
       "     'memory': {'memory_size': 16, 'sequence_length': 16},\n",
       "     'normalize': False,\n",
       "     'num_layers': 1},\n",
       "    'reward_signals': {'extrinsic': {'gamma': 0.99, 'strength': 1.0}},\n",
       "    'summary_freq': 10000,\n",
       "    'time_horizon': 2000,\n",
       "    'trainer_type': 'ppo'}}},\n",
       " 'result': {'mean_reward': -0.13076711568748578,\n",
       "  'std_mean_reward': 0.14214,\n",
       "  'episode_length': 154.391163482666,\n",
       "  'normalised_reward': -0.00013076711568748577}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict[6202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001524721241281006"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_normalised_reward = []\n",
    "\n",
    "for key in sorted_dict:\n",
    "    all_normalised_reward.append(sorted_dict[key][\"result\"][\"normalised_reward\"])\n",
    "\n",
    "np.mean(all_normalised_reward)\n",
    "#all_normalised_reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
