# Default values for userconfig: All bool values set to true.

userconfig:
  # Use build env? Set false for run using the unity editor.
  # Attention: This requieres a manually pre build by the user using the editor if set to true.
  # If true: sensor count and stat file export is used. See option below.
  build: true

  # Production mode? Bool requiered. Set to false if ml-agents is not to be run.
  production: true

  # "true" to generate summary file.
  summary: true

  # Set to false to delete all files after the programm finishes.
  keep_files: true

  # Initialize from existing previous run.
  not_based_on_previous_nn: true

  # Provide run id of previous NN to be used for new run.
  # Only used if not_based_on_previous_nn: false is used.
  previous_run_id: 1410

  # Specify number of parallel env to use. Default = 1.
  num_env: 1

  # Number of parallel processes. Default = 1.
  num_process: 1

  # Provide message for the log file for better traceability.
  message: "See log file."

# Set unity enviroment specific options.
# Contains all settings directly passed to the unity environemt via a JSON config file loaded
# during inital loading of the Unity environment.
env_config:
  # Define number of horizontal sensors. Can be single int or a list of int.
  sensorCount: [1, 2, 4]

# Paths used by the python script to generate, save and load files.
paths:
  working_dir: "./python/basic_rl_env"

  # If a pre-build Unity environment is used, provided here path to the enviroment.
  unity_env: "C:/build/windows"
  
  # Data folder in the build env dir. Config file for the env is stored and loaded here.
  unity_env_data: "C:/build/windows/basic_rl_environment_Data"

  # Need to save env config file to the editor, if editor is used.
  unity_assets: "C:/Users/max.muehlefeldt/Documents/GitHub/unity-machine-learning/unity/basic_rl_environment/Assets"

  # Where to store the log files generated by the script.
  log_dir: "./logs"

  # Python script generates after the ml-agents runs a summary file.
  summaries_dir: "./summaries"

  # Dir where ml-agents saves the results of the runs. Same dir is accessed by tensorboard.
  results_dir: "./results"

  # Dir to store old results of ml-agents. Dirs from results_dir can be moved by hand here.
  results_archive_dir: "./results_archive"

  # Dir to store configs for ml-agents.
  configs_dir: "./configs"

  # Dir to store the configuration files loaded by unity to configure the env.
  unity_configs_dir: "./unity_configs"

  # Define path of the stats file to be exported at the end of the ml-agents run.
  # Stats file is created by Unity code and provides more detail about the run.
  # Naming convention needs to be so. Do not change.
  # Path is added to the Unity env config file.
  statsExportPath: "./stats"



# ML-Agents configuration.
behaviors:
  RollerAgent:
    # Common Trainer Configurations.
    trainer_type: ppo
    keep_checkpoints: 5
    max_steps: 2e6
    time_horizon: 1540
    summary_freq: 10000

    hyperparameters:
      # Common Trainer Configurations.
      batch_size: 356
      buffer_size: 102400
      learning_rate: 1e-3
      learning_rate_schedule: linear

      # PPO-specific Configurations.
      beta: 1e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      
    network_settings:
      conditioning_type: none # Can be none, because no goal observation is used.
      normalize: false
      hidden_units: 512
      num_layers: 1
      memory:
        memory_size: 128
        sequence_length: 64
      #vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      #curiosity:
      #  strength: 1.0
      #  gamma: 0.99
      #  learning_rate: 3e-4
      #  network_settings: 
      #   hidden_units: 128
      
    


    
